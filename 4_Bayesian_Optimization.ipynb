{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c36a58d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4d848eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\illew\\anaconda3\\envs\\rdkit_tf-gpu\\lib\\site-packages\\torch_geometric\\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.datasets import MoleculeNet\n",
    "\n",
    "data = MoleculeNet(root=\".\", name=\"ESOL\")\n",
    "data_size = len(data)\n",
    "NUM_GRAPHS_PER_BATCH = 32\n",
    "loader = DataLoader(data[:int(data_size * 0.7)], batch_size=NUM_GRAPHS_PER_BATCH, shuffle = False)\n",
    "test_loader = DataLoader(data[int(data_size * 0.7):int(data_size * 0.9)], batch_size=NUM_GRAPHS_PER_BATCH, shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1fcbacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary:\n",
      ". #()/12345678=BCFHINOPS[\\]clnors\n",
      "34\n",
      "Encoding Test:\n",
      "[17, 28, 7, 31, 28, 28, 28, 7, 17, 4, 15, 22, 5, 21, 28, 8, 28, 28, 28, 28, 28, 8]\n",
      "Cc1occc1C(=O)Nc2ccccc2\n"
     ]
    }
   ],
   "source": [
    "# Embed SMILES into numbers\n",
    "\n",
    "# Get set of characters\n",
    "chars = set()\n",
    "for i in data.smiles:\n",
    "    for letter in i:\n",
    "        chars.add(letter) \n",
    "chars = ['.']+sorted(list(chars))\n",
    "vocab_size = len(chars)+1 #plus one for padding \"end\" type char\n",
    "print('Vocabulary:')\n",
    "print(''.join(chars))\n",
    "print(vocab_size)\n",
    "\n",
    "# Map characters to integers\n",
    "stoi = {ch:i+1 for i,ch in enumerate(chars)}\n",
    "itos = {i+1:ch for i,ch in enumerate(chars)}\n",
    "encode = lambda st: [stoi[ch] for ch in st]\n",
    "decode = lambda nu: ''.join([itos[int(i)] for i in nu])\n",
    "print('Encoding Test:')\n",
    "print(encode('Cc1occc1C(=O)Nc2ccccc2'))\n",
    "print(decode(encode('Cc1occc1C(=O)Nc2ccccc2')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db3c2887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n"
     ]
    }
   ],
   "source": [
    "# Get max length for padding\n",
    "max_length = 0\n",
    "for i in data.smiles:\n",
    "    if len(i)>max_length:\n",
    "        max_length = len(i)\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7db34aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add padded encodings to dataset\n",
    "def add_attributes(dataset):\n",
    "    data_list = []\n",
    "    for data in dataset:\n",
    "        data.encsmiles = encode(data.smiles)+[0 for _ in range(len(encode(data.smiles)),max_length)]\n",
    "        data_list.append(data)\n",
    "    dataset.data, dataset.slices = dataset.collate(data_list)\n",
    "    return dataset\n",
    "\n",
    "data = add_attributes(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c9c51e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n",
      "[22, 17, 17, 9, 22, 17, 4, 22, 17, 17, 8, 22, 17, 4, 22, 17, 4, 17, 3, 21, 5, 28, 7, 28, 28, 28, 28, 28, 7, 5, 17, 4, 22, 5, 17, 4, 22, 5, 17, 8, 22, 5, 17, 4, 22, 5, 17, 4, 22, 5, 17, 9, 22, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([[-0.7700]])\n"
     ]
    }
   ],
   "source": [
    "# Check encoded smiles\n",
    "print(len(data[0].encsmiles))\n",
    "print(data[0].encsmiles)\n",
    "print(data[0].y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "861f81ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 98]) torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "# Test batch\n",
    "batch_size = 32\n",
    "xb = torch.tensor(data[:batch_size].encsmiles)\n",
    "yb = data[:batch_size].y\n",
    "print(xb.size(),yb.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b693b365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Parameters:  8513\n"
     ]
    }
   ],
   "source": [
    "# Now the task - to connect sequence [data.encsmiles] to solubility [data.y]\n",
    "# Framework of sentiment analysis, where the passage is [data.encsmiles] and the sentiment is [data.y]\n",
    "# https://towardsdatascience.com/build-your-own-transformer-from-scratch-using-pytorch-84c850470dcb\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import Linear\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = max_length):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        position = torch.arange(max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0)/d_model))\n",
    "\n",
    "        pe = torch.zeros(1, max_len, d_model) # Batch, Token, Channel \n",
    "        pe[0,:,0::2] = torch.sin(position*div_term)\n",
    "        pe[0,:,1::2] = torch.cos(position*div_term) \n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:,:x.size(1)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert d_model % num_heads == 0, \"model dimensionality d_model must be divisible by num_heads\"\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads # dimensions per head\n",
    "        \n",
    "        self.W_q = nn.Linear(d_model,d_model)\n",
    "        self.W_k = nn.Linear(d_model,d_model)\n",
    "        self.W_v = nn.Linear(d_model,d_model)\n",
    "        self.W_o = nn.Linear(d_model,d_model)\n",
    "        \n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        # Get similarities between queries and keys\n",
    "        attention_scores = Q @ K.transpose(-2,-1) / math.sqrt(self.d_k)\n",
    "        \n",
    "        # Mask if present\n",
    "        if mask is not None:\n",
    "            attention_scores = attention_scores.masked_fill(mask == 0, -1e9)\n",
    "        \n",
    "        # Softmax to get proportional weights for value aggregation\n",
    "        attention_probability = torch.softmax(attention_scores, dim=-1)\n",
    "        output_values = attention_probability @ V\n",
    "        return output_values\n",
    "    \n",
    "    def split_heads(self, x):\n",
    "        batch_size, seq_length, d_model = x.size()\n",
    "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1,2)\n",
    "    \n",
    "    def combine_heads(self, x):\n",
    "        batch_size, heads, seq_length, d_k = x.size()\n",
    "        return x.transpose(1,2).contiguous().view(batch_size, seq_length, self.d_model)\n",
    "    \n",
    "    def forward(self, embedding, mask=None):\n",
    "        # Multi head split\n",
    "        Q = self.split_heads(self.W_q(embedding))\n",
    "        K = self.split_heads(self.W_k(embedding))\n",
    "        V = self.split_heads(self.W_v(embedding))\n",
    "        \n",
    "        # Attention\n",
    "        attention_output = self.scaled_dot_product_attention(Q,K,V, mask)\n",
    "        \n",
    "        # Merge heads and output\n",
    "        output = self.W_o(self.combine_heads(attention_output))\n",
    "        return output\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, vocab_size=34, dropout=.1):\n",
    "        super(Encoder,self).__init__()\n",
    "        \n",
    "        # Embedding\n",
    "        self.embedding = nn.Embedding(vocab_size,d_model)\n",
    "        \n",
    "        # Positional Encoding\n",
    "        self.pos_encoder = PositionalEncoding(d_model)\n",
    "        \n",
    "        # Attention\n",
    "        self.self_attention = MultiHeadAttention(d_model, num_heads)\n",
    "        \n",
    "        # Linear\n",
    "        self.linear = Linear(max_length*d_model, 1)\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, idx, targets=None):\n",
    "        # embedding\n",
    "        logits = self.embedding(idx) # (B,T,C)\n",
    "        \n",
    "        # positional encoding \n",
    "        logits = self.pos_encoder(logits)\n",
    "        \n",
    "        # attention\n",
    "        attend = self.self_attention(logits)\n",
    "        \n",
    "        # residual\n",
    "        logits = logits + self.dropout(attend)\n",
    "        logits = self.norm(logits)\n",
    "        \n",
    "        # output\n",
    "        batch_size, seq_length, d_model = logits.size()\n",
    "        logits = logits.contiguous().view(batch_size, seq_length*d_model)\n",
    "        output = self.linear(logits)\n",
    "        loss = F.mse_loss(output,targets)    \n",
    "        return output, loss \n",
    "    \n",
    "    def generate(self, idx): #trivial here, but left for later generalizability\n",
    "        logits, loss = self(idx)\n",
    "        return logits\n",
    "\n",
    "emb_size = 32\n",
    "num_heads = emb_size//8\n",
    "dropout = 0.1\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') \n",
    "m = Encoder(emb_size, num_heads, vocab_size, dropout).to(device)\n",
    "\n",
    "xb=xb.to(device)\n",
    "yb=yb.to(device)\n",
    "output, loss = m(xb,yb)\n",
    "# print(output, yb, loss.item())  \n",
    "\n",
    "print(\"Number of Parameters: \", sum(p.numel() for p in m.parameters()))\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c87f7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\illew\\AppData\\Local\\Temp/ipykernel_21216/150668724.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_encsmiles, val_y = torch.tensor(val.encsmiles, device=device), torch.tensor(val.y, device=device)\n"
     ]
    }
   ],
   "source": [
    "# Data loader\n",
    "batch_size = 32\n",
    "loader = DataLoader(data[:int(data_size * 0.7)], batch_size=batch_size, shuffle = False)\n",
    "test_loader = DataLoader(data[int(data_size * 0.7):int(data_size * 0.9)], batch_size=batch_size, shuffle = False)\n",
    "val_loader = DataLoader(data[int(data_size * 0.9):], batch_size=batch_size, shuffle = False)\n",
    "\n",
    "val = data[int(data_size * 0.9):int(data_size * 0.9)+batch_size]\n",
    "val_encsmiles, val_y = torch.tensor(val.encsmiles, device=device), torch.tensor(val.y, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa7f5bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hyperparameter Search via Bayesian Optimization\n",
    "\n",
    "# Helper functions\n",
    "\n",
    "# Search Space: embedding size(halved), num_heads, dropout\n",
    "emb_range = [1,8] # will be multiplied by 2 to enforce evens only\n",
    "heads_range = [1,16]\n",
    "dropout_range = [0,1]\n",
    "\n",
    "# Objective Function:\n",
    "    # takes in hyper parameters\n",
    "    # creates model\n",
    "    # trains model\n",
    "    # evaluates model on full validation set\n",
    "    # returns final validation error\n",
    "\n",
    "# Objective function to optimize: Transformer encoder\n",
    "def objective(X, Y=[[10]]):\n",
    "    emb_per_head = X[0]\n",
    "    num_heads = X[1]\n",
    "    dropout = X[2]\n",
    "    \n",
    "    # Create Model\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    m = Encoder(num_heads*emb_per_head, num_heads, 34, dropout).to(device)\n",
    "    optimizer = torch.optim.Adam(m.parameters(), lr=0.01)\n",
    "    print('Model created with', num_heads, 'heads,', emb_per_head, 'dimensions per head, and', dropout, 'dropout.')\n",
    "    \n",
    "    # Train Model\n",
    "    for epoch in range(200):\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            property_prediction, loss = m(torch.tensor(batch.encsmiles), batch.y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if epoch % 10 == 0:\n",
    "            print(epoch,loss.item())\n",
    "    \n",
    "    # Validation Loss\n",
    "    val_losses = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch = batch.to(device)\n",
    "            val_property_prediction, val_loss = m(torch.tensor(batch.encsmiles), batch.y)\n",
    "            val_losses.append(val_loss)\n",
    "    avg_val_loss = sum(val_losses)/len(val_losses)\n",
    "    print('Validation loss:', avg_val_loss.item())\n",
    "    \n",
    "    if avg_val_loss <= min(Y)[0]:\n",
    "        torch.save(m,'011023_BO_tenc.pt')\n",
    "    \n",
    "    return avg_val_loss\n",
    "\n",
    "# Surrogate function for Bayesian optimization: \n",
    "    # Common types include Gaussian Process, Random Forest, Tree-structured Parzen Estimator...\n",
    "    # Here we use gaussian process\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "def surrogate(model, X):\n",
    "    # Returns mean and std for stack of historical hyperparameters X\n",
    "    return model.predict(X, return_std=True) \n",
    "    \n",
    "# Acquisition function for scoring exploration: \n",
    "    # Common types include Probability of Improvement, Expected Improvement, Lower Confidence Bound\n",
    "    # Evaluates liklihood that given candidate sample is worth evaluating with real objective function\n",
    "from scipy.stats import norm\n",
    "def acquisition(X, Xsample, model):\n",
    "    # For previous hyperparameters [X], new proposed hyperparameters [Xsamples], surrogate model [model]\n",
    "    # Get score of whether new hyperparameters are worthy to check\n",
    "    \n",
    "    # Current best hyperparameter performance\n",
    "    old_mean, old_std = surrogate(model, X) \n",
    "    best_mean = min(old_mean)\n",
    "    \n",
    "    # New hyperparameter performance\n",
    "    new_mean, new_std = surrogate(model, Xsample)\n",
    "    probability = norm.cdf((new_mean - best_mean)/(new_std + 1e-9))\n",
    "    return probability\n",
    "\n",
    "# Selection function for potential acquisitions:\n",
    "    # Common types include random and grid selection\n",
    "    # Here, random is implemented\n",
    "import random\n",
    "def selection(X, model):\n",
    "    scores = {}\n",
    "    for samples in range(100):\n",
    "        Xsample = [[random.randint(emb_range[0],emb_range[1])*2, random.randint(heads_range[0],heads_range[1]), random.uniform(dropout_range[0],dropout_range[1])]] # num_heads, emb_per_head, dropout\n",
    "        scores[tuple(Xsample[0])] = acquisition(X,Xsample,model)\n",
    "    best_hyper = min(zip(scores.values(),scores.keys()))[1]\n",
    "    return list(best_hyper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a034b519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created with 2 heads, 4 dimensions per head, and 0.6210600561452275 dropout.\n",
      "0 3.129314661026001\n",
      "10 0.8885423541069031\n",
      "20 0.5401342511177063\n",
      "30 0.7239106297492981\n",
      "40 0.6235337853431702\n",
      "50 0.44746172428131104\n",
      "60 0.6620482802391052\n",
      "70 0.9279161095619202\n",
      "80 0.5544934272766113\n",
      "90 0.6160069108009338\n",
      "100 0.6133071780204773\n",
      "110 0.5373317003250122\n",
      "120 0.545931339263916\n",
      "130 0.3655525743961334\n",
      "140 0.40236565470695496\n",
      "150 0.5721831917762756\n",
      "160 0.47537437081336975\n",
      "170 0.48329514265060425\n",
      "180 0.702710747718811\n",
      "190 0.4674127697944641\n",
      "Validation loss: 0.9918512105941772\n",
      "Model created with 10 heads, 2 dimensions per head, and 0.03727480756531776 dropout.\n",
      "0 3.9929847717285156\n",
      "10 0.8542195558547974\n",
      "20 0.3921286463737488\n",
      "30 1.0414977073669434\n",
      "40 0.26055485010147095\n",
      "50 0.3400370478630066\n",
      "60 0.2099018096923828\n",
      "70 0.13082768023014069\n",
      "80 0.1825283020734787\n",
      "90 0.23830664157867432\n",
      "100 0.22419852018356323\n",
      "110 0.18883894383907318\n",
      "120 0.11005659401416779\n",
      "130 0.25626352429389954\n",
      "140 0.09912186861038208\n",
      "150 0.15486758947372437\n",
      "160 0.13929861783981323\n",
      "170 0.24089495837688446\n",
      "180 0.22490808367729187\n",
      "190 0.20652493834495544\n",
      "Validation loss: 0.9339483976364136\n",
      "Model created with 5 heads, 8 dimensions per head, and 0.7694383994327705 dropout.\n",
      "0 11.902471542358398\n",
      "10 1.6279937028884888\n",
      "20 0.7021161913871765\n",
      "30 0.6569916605949402\n",
      "40 0.41395479440689087\n",
      "50 0.528076708316803\n",
      "60 0.3273812234401703\n",
      "70 0.4749549329280853\n",
      "80 0.24222306907176971\n",
      "90 0.4680677354335785\n",
      "100 0.5166003704071045\n",
      "110 0.28959786891937256\n",
      "120 0.27345702052116394\n",
      "130 0.28595319390296936\n",
      "140 0.3025314211845398\n",
      "150 0.39239126443862915\n",
      "160 0.1789388209581375\n",
      "170 0.19377106428146362\n",
      "180 0.19990943372249603\n",
      "190 0.43302369117736816\n",
      "Validation loss: 1.1197524070739746\n",
      "Model created with 7 heads, 14 dimensions per head, and 0.9199563182132603 dropout.\n",
      "0 10.405194282531738\n",
      "10 3.243725061416626\n",
      "20 1.255046010017395\n",
      "30 0.7788097262382507\n",
      "40 1.1560081243515015\n",
      "50 0.5923416614532471\n",
      "60 0.9606397747993469\n",
      "70 1.3586612939834595\n",
      "80 0.732970654964447\n",
      "90 0.6889292597770691\n",
      "100 0.6068997979164124\n",
      "110 0.6779732704162598\n",
      "120 0.26769310235977173\n",
      "130 0.5130160450935364\n",
      "140 0.5674529075622559\n",
      "150 0.6952349543571472\n",
      "160 0.28645944595336914\n",
      "170 0.46095186471939087\n",
      "180 0.8078189492225647\n",
      "190 0.7833388447761536\n",
      "Validation loss: 0.992186427116394\n",
      "Model created with 7 heads, 6 dimensions per head, and 0.35582139971279203 dropout.\n",
      "0 10.409120559692383\n",
      "10 0.8097740411758423\n",
      "20 0.4473397433757782\n",
      "30 0.5377819538116455\n",
      "40 0.6061175465583801\n",
      "50 0.5512240529060364\n",
      "60 0.25109630823135376\n",
      "70 0.19810111820697784\n",
      "80 0.17882852256298065\n",
      "90 0.16801369190216064\n",
      "100 0.35015806555747986\n",
      "110 0.12428810447454453\n",
      "120 0.11869419366121292\n",
      "130 0.28602951765060425\n",
      "140 0.2266763150691986\n",
      "150 0.22011630237102509\n",
      "160 0.188349649310112\n",
      "170 0.3129870593547821\n",
      "180 0.36218908429145813\n",
      "190 0.16101768612861633\n",
      "Validation loss: 1.0688291788101196\n",
      "Model created with 6 heads, 12 dimensions per head, and 0.6083950422987784 dropout.\n",
      "0 20.901262283325195\n",
      "10 2.7817840576171875\n",
      "20 0.8444414734840393\n",
      "30 0.6947436928749084\n",
      "40 0.3527015447616577\n",
      "50 0.7136870622634888\n",
      "60 0.8436065316200256\n",
      "70 0.5248520374298096\n",
      "80 0.6544744968414307\n",
      "90 0.5621214509010315\n",
      "100 0.4992678463459015\n",
      "110 0.42814937233924866\n",
      "120 0.35594749450683594\n",
      "130 0.3576603829860687\n",
      "140 0.4918886125087738\n",
      "150 0.36731424927711487\n",
      "160 1.0414973497390747\n",
      "170 0.7878702282905579\n",
      "180 0.31878581643104553\n",
      "190 0.3434315621852875\n",
      "Validation loss: 0.9166784882545471\n",
      "Model created with 4 heads, 6 dimensions per head, and 0.23163809184374773 dropout.\n",
      "0 4.373847007751465\n",
      "10 0.8032002449035645\n",
      "20 1.1156452894210815\n",
      "30 0.28150126338005066\n",
      "40 0.8902667760848999\n",
      "50 0.430009126663208\n",
      "60 0.2329668402671814\n",
      "70 0.2298596054315567\n",
      "80 0.3547208905220032\n",
      "90 0.2101788967847824\n",
      "100 0.3067358434200287\n",
      "110 0.19414256513118744\n",
      "120 0.17947104573249817\n",
      "130 0.13888058066368103\n",
      "140 0.1102166622877121\n",
      "150 0.1381751298904419\n",
      "160 0.18397854268550873\n",
      "170 0.1556423157453537\n",
      "180 0.14622393250465393\n",
      "190 0.2582570016384125\n",
      "Validation loss: 1.057592511177063\n",
      "Model created with 11 heads, 2 dimensions per head, and 0.015953341070105487 dropout.\n",
      "0 5.3234124183654785\n",
      "10 0.44167232513427734\n",
      "20 0.6997016668319702\n",
      "30 0.6190425157546997\n",
      "40 0.3141641616821289\n",
      "50 0.13666799664497375\n",
      "60 0.14412249624729156\n",
      "70 0.31063973903656006\n",
      "80 0.1024344339966774\n",
      "90 0.16589809954166412\n",
      "100 0.25107428431510925\n",
      "110 0.08537952601909637\n",
      "120 0.14878453314304352\n",
      "130 0.19745250046253204\n",
      "140 0.08881400525569916\n",
      "150 0.1401621550321579\n",
      "160 0.28307655453681946\n",
      "170 0.3540206253528595\n",
      "180 0.10540317744016647\n",
      "190 0.14582771062850952\n",
      "Validation loss: 1.0469948053359985\n",
      "Model created with 14 heads, 2 dimensions per head, and 0.06832355069447815 dropout.\n",
      "0 6.380732536315918\n",
      "10 0.4928208887577057\n",
      "20 0.3511745035648346\n",
      "30 0.2255416214466095\n",
      "40 0.22589057683944702\n",
      "50 0.18613354861736298\n",
      "60 0.2862425744533539\n",
      "70 0.14906719326972961\n",
      "80 0.17501123249530792\n",
      "90 0.23033379018306732\n",
      "100 0.2191055715084076\n",
      "110 0.09451131522655487\n",
      "120 0.18690285086631775\n",
      "130 0.2551426291465759\n",
      "140 0.10417193919420242\n",
      "150 0.14105552434921265\n",
      "160 0.15743479132652283\n",
      "170 0.42521655559539795\n",
      "180 0.20725640654563904\n",
      "190 0.1427595019340515\n",
      "Validation loss: 0.9033409953117371\n",
      "Model created with 6 heads, 8 dimensions per head, and 0.8673156523400238 dropout.\n",
      "0 8.578874588012695\n",
      "10 2.0420103073120117\n",
      "20 2.38090181350708\n",
      "30 0.9067127704620361\n",
      "40 0.9829118251800537\n",
      "50 1.193104863166809\n",
      "60 0.3920741379261017\n",
      "70 0.9667968153953552\n",
      "80 0.7407041788101196\n",
      "90 0.3065054714679718\n",
      "100 0.3891858756542206\n",
      "110 0.4313470721244812\n",
      "120 0.4461555480957031\n",
      "130 0.50242680311203\n",
      "140 0.49387407302856445\n",
      "150 0.3452994227409363\n",
      "160 0.4331330358982086\n",
      "170 0.581870436668396\n",
      "180 0.5353212952613831\n",
      "190 0.4804607331752777\n",
      "Validation loss: 1.0047919750213623\n",
      "Model created with 16 heads, 12 dimensions per head, and 0.10052457129628134 dropout.\n",
      "0 26.17437171936035\n",
      "10 3.274813413619995\n",
      "20 2.6486496925354004\n",
      "30 1.78260338306427\n",
      "40 5.170310974121094\n",
      "50 1.1026049852371216\n",
      "60 0.7042638659477234\n",
      "70 0.5725945234298706\n",
      "80 0.4871058762073517\n",
      "90 0.39575546979904175\n",
      "100 0.6345301866531372\n",
      "110 0.610522449016571\n",
      "120 0.21470984816551208\n",
      "130 0.18799151480197906\n",
      "140 0.2203570306301117\n",
      "150 0.1134057268500328\n",
      "160 0.23574116826057434\n",
      "170 0.18521203100681305\n",
      "180 0.2080545723438263\n",
      "190 0.24050915241241455\n",
      "Validation loss: 1.1603829860687256\n",
      "0 Selected hyperparameters: [12, 16, 0.10052457129628134] Estimated Loss: 2.3104224227858593e-19 Real Loss: 1.1603829860687256\n",
      "Model created with 1 heads, 16 dimensions per head, and 0.7718576391772058 dropout.\n",
      "0 4.647074222564697\n",
      "10 1.3496248722076416\n",
      "20 1.0063116550445557\n",
      "30 0.5071274638175964\n",
      "40 0.79923415184021\n",
      "50 0.4155054986476898\n",
      "60 1.4560489654541016\n",
      "70 0.3403208255767822\n",
      "80 0.49480947852134705\n",
      "90 0.506553590297699\n",
      "100 0.3994264304637909\n",
      "110 0.2710246741771698\n",
      "120 0.4783465266227722\n",
      "130 0.6394070386886597\n",
      "140 0.5649781823158264\n",
      "150 0.3778683543205261\n",
      "160 0.4332877993583679\n",
      "170 0.44345930218696594\n",
      "180 0.46278518438339233\n",
      "190 0.46638208627700806\n",
      "Validation loss: 1.0120384693145752\n",
      "1 Selected hyperparameters: [16, 1, 0.7718576391772058] Estimated Loss: 2.9292717276929174e-09 Real Loss: 1.0120384693145752\n",
      "Model created with 13 heads, 16 dimensions per head, and 0.6610459704938821 dropout.\n",
      "0 116.94219970703125\n",
      "10 8.197687149047852\n",
      "20 4.97607946395874\n",
      "30 2.614119529724121\n",
      "40 2.3428092002868652\n",
      "50 1.650917410850525\n",
      "60 3.0071215629577637\n",
      "70 0.7847071290016174\n",
      "80 0.41805317997932434\n",
      "90 0.5343501567840576\n",
      "100 0.28418901562690735\n",
      "110 0.5477673411369324\n",
      "120 0.44339272379875183\n",
      "130 0.30947786569595337\n",
      "140 0.1649853140115738\n",
      "150 0.262949675321579\n",
      "160 0.2782488763332367\n",
      "170 0.3028911352157593\n",
      "180 0.5664654970169067\n",
      "190 0.5025758147239685\n",
      "Validation loss: 0.9890459775924683\n",
      "2 Selected hyperparameters: [16, 13, 0.6610459704938821] Estimated Loss: 3.6975408136885534e-06 Real Loss: 0.9890459775924683\n",
      "Model created with 12 heads, 8 dimensions per head, and 0.7999192737221701 dropout.\n",
      "0 7.358706474304199\n",
      "10 3.4005520343780518\n",
      "20 1.7434885501861572\n",
      "30 0.7918946743011475\n",
      "40 0.6208037734031677\n",
      "50 0.41646069288253784\n",
      "60 0.41731080412864685\n",
      "70 0.6121559739112854\n",
      "80 0.6399658918380737\n",
      "90 0.48559752106666565\n",
      "100 0.6753688454627991\n",
      "110 0.5484200716018677\n",
      "120 0.29572856426239014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 0.46467941999435425\n",
      "140 0.489920973777771\n",
      "150 0.30273473262786865\n",
      "160 0.34952813386917114\n",
      "170 0.5164046883583069\n",
      "180 0.5003222227096558\n",
      "190 0.22028085589408875\n",
      "Validation loss: 0.8237929940223694\n",
      "3 Selected hyperparameters: [8, 12, 0.7999192737221701] Estimated Loss: 5.790694844949568e-07 Real Loss: 0.8237929940223694\n",
      "Model created with 1 heads, 10 dimensions per head, and 0.18327773301761485 dropout.\n",
      "0 4.203772068023682\n",
      "10 0.6936897039413452\n",
      "20 0.6877137422561646\n",
      "30 0.6889724731445312\n",
      "40 0.7370103597640991\n",
      "50 0.723759114742279\n",
      "60 0.45986050367355347\n",
      "70 0.5273692607879639\n",
      "80 0.4696061313152313\n",
      "90 0.7215970754623413\n",
      "100 0.608544111251831\n",
      "110 0.5683578252792358\n",
      "120 0.2693885564804077\n",
      "130 0.43668773770332336\n",
      "140 0.3163004517555237\n",
      "150 0.42597249150276184\n",
      "160 0.291151225566864\n",
      "170 0.19655674695968628\n",
      "180 0.3314732313156128\n",
      "190 0.337778776884079\n",
      "Validation loss: 0.9285274147987366\n",
      "4 Selected hyperparameters: [10, 1, 0.18327773301761485] Estimated Loss: 3.3081228781558365e-05 Real Loss: 0.9285274147987366\n",
      "Model created with 11 heads, 12 dimensions per head, and 0.632354141305143 dropout.\n",
      "0 61.55195617675781\n",
      "10 4.091337203979492\n",
      "20 2.96516752243042\n",
      "30 1.5866042375564575\n",
      "40 0.8539860248565674\n",
      "50 1.0058002471923828\n",
      "60 0.3348672091960907\n",
      "70 0.4448683559894562\n",
      "80 0.386550635099411\n",
      "90 0.3921510577201843\n",
      "100 0.2846832871437073\n",
      "110 0.24022063612937927\n",
      "120 0.5108644366264343\n",
      "130 0.24237783253192902\n",
      "140 0.313584566116333\n",
      "150 0.23572763800621033\n",
      "160 0.2545837163925171\n",
      "170 0.47965213656425476\n",
      "180 0.3617802858352661\n",
      "190 0.5755725502967834\n",
      "Validation loss: 1.2267556190490723\n",
      "5 Selected hyperparameters: [12, 11, 0.632354141305143] Estimated Loss: 0.0002574072934429236 Real Loss: 1.2267556190490723\n",
      "Model created with 16 heads, 6 dimensions per head, and 0.863322296810275 dropout.\n",
      "0 11.555034637451172\n",
      "10 3.6248373985290527\n",
      "20 1.795151710510254\n",
      "30 1.3091837167739868\n",
      "40 0.8895363807678223\n",
      "50 0.5056044459342957\n",
      "60 0.7302151322364807\n",
      "70 0.22807016968727112\n",
      "80 0.18089477717876434\n",
      "90 0.9418462514877319\n",
      "100 0.36624953150749207\n",
      "110 0.3333125710487366\n",
      "120 0.274410605430603\n",
      "130 0.42555859684944153\n",
      "140 0.4239736497402191\n",
      "150 0.5044607520103455\n",
      "160 0.2949380576610565\n",
      "170 0.44262078404426575\n",
      "180 0.33760371804237366\n",
      "190 0.6821181178092957\n",
      "Validation loss: 1.0176317691802979\n",
      "6 Selected hyperparameters: [6, 16, 0.863322296810275] Estimated Loss: 6.694847380529732e-05 Real Loss: 1.0176317691802979\n",
      "Model created with 16 heads, 16 dimensions per head, and 0.4823528198582133 dropout.\n",
      "0 307.9912109375\n",
      "10 5.930505275726318\n",
      "20 5.130974769592285\n",
      "30 2.20350980758667\n",
      "40 4.0084991455078125\n",
      "50 1.3990072011947632\n",
      "60 0.6886409521102905\n",
      "70 1.460820198059082\n",
      "80 0.49758386611938477\n",
      "90 1.0665959119796753\n",
      "100 1.0558933019638062\n",
      "110 1.8817058801651\n",
      "120 0.3134780824184418\n",
      "130 0.4389747381210327\n",
      "140 0.36259040236473083\n",
      "150 0.4277381896972656\n",
      "160 0.30383938550949097\n",
      "170 0.24774570763111115\n",
      "180 0.35290610790252686\n",
      "190 0.08359650522470474\n",
      "Validation loss: 0.8552193641662598\n",
      "7 Selected hyperparameters: [16, 16, 0.4823528198582133] Estimated Loss: 0.011174531038679242 Real Loss: 0.8552193641662598\n",
      "Model created with 7 heads, 2 dimensions per head, and 0.05811719176012198 dropout.\n",
      "0 3.326845407485962\n",
      "10 1.1480498313903809\n",
      "20 0.6833224892616272\n",
      "30 0.558268666267395\n",
      "40 0.7367092370986938\n",
      "50 0.21126434206962585\n",
      "60 0.1449015885591507\n",
      "70 0.43185386061668396\n",
      "80 0.21125034987926483\n",
      "90 0.36899468302726746\n",
      "100 0.18131966888904572\n",
      "110 0.1630304902791977\n",
      "120 0.19295448064804077\n",
      "130 0.19858169555664062\n",
      "140 0.25101104378700256\n",
      "150 0.21764013171195984\n",
      "160 0.22545769810676575\n",
      "170 0.13894686102867126\n",
      "180 0.517863392829895\n",
      "190 0.32325008511543274\n",
      "Validation loss: 0.9057449102401733\n",
      "8 Selected hyperparameters: [2, 7, 0.05811719176012198] Estimated Loss: 0.005932034590344998 Real Loss: 0.9057449102401733\n",
      "Model created with 10 heads, 16 dimensions per head, and 0.25145011084792535 dropout.\n",
      "0 52.90754318237305\n",
      "10 3.208265542984009\n",
      "20 2.4675023555755615\n",
      "30 3.434441328048706\n",
      "40 4.034684658050537\n",
      "50 4.244923114776611\n",
      "60 3.3810105323791504\n",
      "70 0.737073540687561\n",
      "80 0.842866837978363\n",
      "90 0.574954092502594\n",
      "100 0.5350578427314758\n",
      "110 0.6021548509597778\n",
      "120 0.3228406012058258\n",
      "130 0.34476158022880554\n",
      "140 0.2769543528556824\n",
      "150 0.35756585001945496\n",
      "160 0.4020176827907562\n",
      "170 0.3130616247653961\n",
      "180 0.23034514486789703\n",
      "190 0.2792220413684845\n",
      "Validation loss: 0.9275147914886475\n",
      "9 Selected hyperparameters: [16, 10, 0.25145011084792535] Estimated Loss: 0.011354126426717005 Real Loss: 0.9275147914886475\n",
      "Model created with 5 heads, 16 dimensions per head, and 0.5453617602695666 dropout.\n",
      "0 30.201730728149414\n",
      "10 2.595048427581787\n",
      "20 2.834766387939453\n",
      "30 3.5420539379119873\n",
      "40 0.6026174426078796\n",
      "50 0.538910448551178\n",
      "60 0.8502904176712036\n",
      "70 0.5039916634559631\n",
      "80 0.3082573413848877\n",
      "90 0.35768553614616394\n",
      "100 0.29332396388053894\n",
      "110 1.4827666282653809\n",
      "120 0.293941855430603\n",
      "130 0.2932654023170471\n",
      "140 0.26482242345809937\n",
      "150 0.1514463573694229\n",
      "160 0.2881717383861542\n",
      "170 0.23823237419128418\n",
      "180 0.31708550453186035\n",
      "190 0.2087777554988861\n",
      "Validation loss: 1.3369426727294922\n",
      "10 Selected hyperparameters: [16, 5, 0.5453617602695666] Estimated Loss: 0.01630014229690875 Real Loss: 1.3369426727294922\n",
      "Model created with 9 heads, 10 dimensions per head, and 0.9012003102169254 dropout.\n",
      "0 15.242588996887207\n",
      "10 5.085017204284668\n",
      "20 1.7771186828613281\n",
      "30 0.9889376759529114\n",
      "40 0.7045005559921265\n",
      "50 0.8367061018943787\n",
      "60 0.7860761284828186\n",
      "70 0.48008763790130615\n",
      "80 0.4664696455001831\n",
      "90 0.4503641128540039\n",
      "100 0.7249853014945984\n",
      "110 0.666991114616394\n",
      "120 0.4506169259548187\n",
      "130 0.4108026623725891\n",
      "140 0.4214530289173126\n",
      "150 0.32261013984680176\n",
      "160 0.38783374428749084\n",
      "170 0.36478322744369507\n",
      "180 0.5586068630218506\n",
      "190 0.3573048412799835\n",
      "Validation loss: 1.0785441398620605\n",
      "11 Selected hyperparameters: [10, 9, 0.9012003102169254] Estimated Loss: 0.024920949149337374 Real Loss: 1.0785441398620605\n",
      "Model created with 3 heads, 12 dimensions per head, and 0.2850130788383841 dropout.\n",
      "0 4.109856605529785\n",
      "10 1.0086733102798462\n",
      "20 0.5794068574905396\n",
      "30 0.5781806111335754\n",
      "40 0.7740694880485535\n",
      "50 0.31835484504699707\n",
      "60 0.32541394233703613\n",
      "70 0.37042251229286194\n",
      "80 0.15598458051681519\n",
      "90 0.34522759914398193\n",
      "100 0.155740424990654\n",
      "110 0.16736507415771484\n",
      "120 0.23426944017410278\n",
      "130 0.1437673419713974\n",
      "140 0.2940202057361603\n",
      "150 0.21769389510154724\n",
      "160 0.3632785379886627\n",
      "170 0.24661926925182343\n",
      "180 0.14730514585971832\n",
      "190 0.2660358250141144\n",
      "Validation loss: 0.991365373134613\n",
      "12 Selected hyperparameters: [12, 3, 0.2850130788383841] Estimated Loss: 0.025981000067841414 Real Loss: 0.991365373134613\n",
      "Model created with 4 heads, 2 dimensions per head, and 0.6613881255227244 dropout.\n",
      "0 3.163877248764038\n",
      "10 1.0240689516067505\n",
      "20 0.6954396963119507\n",
      "30 0.5771675705909729\n",
      "40 1.0410619974136353\n",
      "50 0.3608236312866211\n",
      "60 0.3878556191921234\n",
      "70 0.27578917145729065\n",
      "80 0.43565133213996887\n",
      "90 0.4925859570503235\n",
      "100 0.24232281744480133\n",
      "110 0.28667035698890686\n",
      "120 0.908409059047699\n",
      "130 0.6766484975814819\n",
      "140 0.4098129868507385\n",
      "150 0.40936556458473206\n",
      "160 0.43663689494132996\n",
      "170 0.34582677483558655\n",
      "180 0.5158313512802124\n",
      "190 0.4912293255329132\n",
      "Validation loss: 0.82145756483078\n",
      "13 Selected hyperparameters: [2, 4, 0.6613881255227244] Estimated Loss: 0.02648500462098112 Real Loss: 0.82145756483078\n",
      "Model created with 10 heads, 6 dimensions per head, and 0.6393719852196427 dropout.\n",
      "0 12.505410194396973\n",
      "10 1.5694392919540405\n",
      "20 0.5711400508880615\n",
      "30 0.7696053981781006\n",
      "40 0.5765418410301208\n",
      "50 0.298089861869812\n",
      "60 0.6909307241439819\n",
      "70 0.4236505627632141\n",
      "80 0.46502387523651123\n",
      "90 0.44835132360458374\n",
      "100 0.46345794200897217\n",
      "110 0.4680306315422058\n",
      "120 0.21573561429977417\n",
      "130 0.6139929890632629\n",
      "140 0.4057839810848236\n",
      "150 0.17914213240146637\n",
      "160 0.22583244740962982\n",
      "170 0.4199042320251465\n",
      "180 0.3097546100616455\n",
      "190 0.20823504030704498\n",
      "Validation loss: 0.8133224844932556\n",
      "14 Selected hyperparameters: [6, 10, 0.6393719852196427] Estimated Loss: 0.026148876499581496 Real Loss: 0.8133224844932556\n",
      "Model created with 14 heads, 10 dimensions per head, and 0.0596847599455379 dropout.\n",
      "0 9.053093910217285\n",
      "10 2.194333076477051\n",
      "20 1.9393194913864136\n",
      "30 6.4607954025268555\n",
      "40 2.481351137161255\n",
      "50 0.7218388915061951\n",
      "60 0.5629573464393616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70 0.32050269842147827\n",
      "80 0.18088746070861816\n",
      "90 1.0642765760421753\n",
      "100 0.19048437476158142\n",
      "110 0.12955808639526367\n",
      "120 0.20685788989067078\n",
      "130 0.19017350673675537\n",
      "140 0.18190382421016693\n",
      "150 0.17697523534297943\n",
      "160 0.1548847109079361\n",
      "170 0.10879547148942947\n",
      "180 0.06725029647350311\n",
      "190 0.3087940216064453\n",
      "Validation loss: 1.2174586057662964\n",
      "15 Selected hyperparameters: [10, 14, 0.0596847599455379] Estimated Loss: 0.03405603986008386 Real Loss: 1.2174586057662964\n",
      "Model created with 13 heads, 4 dimensions per head, and 0.820168273741111 dropout.\n",
      "0 16.703418731689453\n",
      "10 2.114781379699707\n",
      "20 1.0051857233047485\n",
      "30 0.28565481305122375\n",
      "40 0.6496890783309937\n",
      "50 0.5493249893188477\n",
      "60 0.559224009513855\n",
      "70 0.31669682264328003\n",
      "80 0.3705795407295227\n",
      "90 0.2754001319408417\n",
      "100 0.44104912877082825\n",
      "110 0.22644168138504028\n",
      "120 0.5401257872581482\n",
      "130 0.22725138068199158\n",
      "140 0.3640102744102478\n",
      "150 0.2956906855106354\n",
      "160 0.3745482265949249\n",
      "170 0.14954914152622223\n",
      "180 0.3235599100589752\n",
      "190 0.35005810856819153\n",
      "Validation loss: 0.8020966649055481\n",
      "16 Selected hyperparameters: [4, 13, 0.820168273741111] Estimated Loss: 0.06872771226707707 Real Loss: 0.8020966649055481\n",
      "Model created with 1 heads, 6 dimensions per head, and 0.06017097531057081 dropout.\n",
      "0 3.586196184158325\n",
      "10 0.8216449618339539\n",
      "20 0.7893493175506592\n",
      "30 0.5931110382080078\n",
      "40 0.7922021746635437\n",
      "50 1.1666852235794067\n",
      "60 0.876338005065918\n",
      "70 0.2663790285587311\n",
      "80 0.44687458872795105\n",
      "90 0.5694589614868164\n",
      "100 0.47717368602752686\n",
      "110 0.4020557105541229\n",
      "120 0.24661782383918762\n",
      "130 0.7744457125663757\n",
      "140 0.4649779200553894\n",
      "150 0.5291175842285156\n",
      "160 0.457476943731308\n",
      "170 0.24377557635307312\n",
      "180 0.5752075910568237\n",
      "190 0.7162532210350037\n",
      "Validation loss: 0.8548731803894043\n",
      "17 Selected hyperparameters: [6, 1, 0.06017097531057081] Estimated Loss: 0.0783346555771774 Real Loss: 0.8548731803894043\n",
      "Model created with 14 heads, 14 dimensions per head, and 0.8997206853170109 dropout.\n",
      "0 24.422697067260742\n",
      "10 6.2883710861206055\n",
      "20 6.0541253089904785\n",
      "30 1.4026732444763184\n",
      "40 1.9107255935668945\n",
      "50 1.1639302968978882\n",
      "60 0.7578544616699219\n",
      "70 0.8785728216171265\n",
      "80 0.8206556439399719\n",
      "90 1.0218359231948853\n",
      "100 1.3982980251312256\n",
      "110 0.7543576955795288\n",
      "120 0.6098544597625732\n",
      "130 0.43407151103019714\n",
      "140 0.6253142952919006\n",
      "150 0.5887612104415894\n",
      "160 0.6707704067230225\n",
      "170 0.4836478531360626\n",
      "180 0.389840692281723\n",
      "190 0.626410186290741\n",
      "Validation loss: 1.004513144493103\n",
      "18 Selected hyperparameters: [14, 14, 0.8997206853170109] Estimated Loss: 0.10880504903564757 Real Loss: 1.004513144493103\n",
      "Model created with 16 heads, 2 dimensions per head, and 0.7435666186928511 dropout.\n",
      "0 6.95456600189209\n",
      "10 1.7486724853515625\n",
      "20 1.1976069211959839\n",
      "30 0.5537427067756653\n",
      "40 0.5634194612503052\n",
      "50 0.3973234295845032\n",
      "60 0.3179263770580292\n",
      "70 0.23278149962425232\n",
      "80 0.3005181550979614\n",
      "90 0.5388562679290771\n",
      "100 0.2971093952655792\n",
      "110 0.13889773190021515\n",
      "120 0.32185885310173035\n",
      "130 0.26478296518325806\n",
      "140 0.5079498887062073\n",
      "150 0.2634736895561218\n",
      "160 0.3336997330188751\n",
      "170 0.28350380063056946\n",
      "180 0.1684977263212204\n",
      "190 0.22331728041172028\n",
      "Validation loss: 0.8781519532203674\n",
      "19 Selected hyperparameters: [2, 16, 0.7435666186928511] Estimated Loss: 0.09296168168085968 Real Loss: 0.8781519532203674\n",
      "Model created with 1 heads, 14 dimensions per head, and 0.028735707903757235 dropout.\n",
      "0 6.978947162628174\n",
      "10 0.6992860436439514\n",
      "20 0.3030657470226288\n",
      "30 0.31885868310928345\n",
      "40 0.3322492837905884\n",
      "50 0.3022156059741974\n",
      "60 0.23228345811367035\n",
      "70 0.23086407780647278\n",
      "80 0.15156719088554382\n",
      "90 0.25605303049087524\n",
      "100 0.3262269198894501\n",
      "110 0.18554140627384186\n",
      "120 0.18746890127658844\n",
      "130 0.31264790892601013\n",
      "140 0.21196579933166504\n",
      "150 0.4408288300037384\n",
      "160 0.1836337447166443\n",
      "170 0.13580411672592163\n",
      "180 0.18693546950817108\n",
      "190 0.2367258369922638\n",
      "Validation loss: 0.6799795627593994\n",
      "20 Selected hyperparameters: [14, 1, 0.028735707903757235] Estimated Loss: 0.12134292797897886 Real Loss: 0.6799795627593994\n",
      "Model created with 1 heads, 2 dimensions per head, and 0.0011417120677029713 dropout.\n",
      "0 5.096987247467041\n",
      "10 4.807470798492432\n",
      "20 2.6755447387695312\n",
      "30 2.051527976989746\n",
      "40 2.195187568664551\n",
      "50 2.2522132396698\n",
      "60 1.4239935874938965\n",
      "70 1.7318854331970215\n",
      "80 1.3740483522415161\n",
      "90 1.7200636863708496\n",
      "100 1.2944093942642212\n",
      "110 1.6177644729614258\n",
      "120 1.3328970670700073\n",
      "130 1.4402050971984863\n",
      "140 1.5246044397354126\n",
      "150 1.0980947017669678\n",
      "160 1.5387641191482544\n",
      "170 1.7818572521209717\n",
      "180 1.4356611967086792\n",
      "190 1.1149543523788452\n",
      "Validation loss: 1.4830873012542725\n",
      "21 Selected hyperparameters: [2, 1, 0.0011417120677029713] Estimated Loss: 0.06876069926516919 Real Loss: 1.4830873012542725\n",
      "Model created with 2 heads, 8 dimensions per head, and 0.7449767969715342 dropout.\n",
      "0 4.068170547485352\n",
      "10 0.7505460381507874\n",
      "20 0.7410954236984253\n",
      "30 1.0665972232818604\n",
      "40 0.3440845310688019\n",
      "50 0.49942708015441895\n",
      "60 0.5161035060882568\n",
      "70 0.6322776675224304\n",
      "80 0.2928144037723541\n",
      "90 0.35908815264701843\n",
      "100 0.6015074849128723\n",
      "110 0.42152586579322815\n",
      "120 0.7700399160385132\n",
      "130 0.5555033683776855\n",
      "140 0.22775210440158844\n",
      "150 0.3743702173233032\n",
      "160 0.5082959532737732\n",
      "170 0.7262423634529114\n",
      "180 0.4601636230945587\n",
      "190 0.40557408332824707\n",
      "Validation loss: 0.8979678153991699\n",
      "22 Selected hyperparameters: [8, 2, 0.7449767969715342] Estimated Loss: 0.13938947845211672 Real Loss: 0.8979678153991699\n",
      "Model created with 14 heads, 6 dimensions per head, and 0.0007933689126157217 dropout.\n",
      "0 9.523242950439453\n",
      "10 0.8993450403213501\n",
      "20 0.5358415246009827\n",
      "30 0.9524679183959961\n",
      "40 0.29486843943595886\n",
      "50 0.5802783370018005\n",
      "60 0.20536774396896362\n",
      "70 0.14398202300071716\n",
      "80 0.17006555199623108\n",
      "90 0.07095123827457428\n",
      "100 0.46543794870376587\n",
      "110 0.09475687891244888\n",
      "120 0.08526097983121872\n",
      "130 0.08156301081180573\n",
      "140 0.07319827377796173\n",
      "150 0.10575857758522034\n",
      "160 0.09963039308786392\n",
      "170 0.1483996957540512\n",
      "180 0.1092531830072403\n",
      "190 0.083458811044693\n",
      "Validation loss: 0.9606180191040039\n",
      "23 Selected hyperparameters: [6, 14, 0.0007933689126157217] Estimated Loss: 0.1496780600625079 Real Loss: 0.9606180191040039\n",
      "Model created with 9 heads, 4 dimensions per head, and 0.7030715984639968 dropout.\n",
      "0 13.266606330871582\n",
      "10 1.6475517749786377\n",
      "20 0.6306325197219849\n",
      "30 0.712946355342865\n",
      "40 0.916557788848877\n",
      "50 0.4059435725212097\n",
      "60 0.4071272909641266\n",
      "70 0.455600380897522\n",
      "80 0.387412428855896\n",
      "90 0.2973785102367401\n",
      "100 0.5010297298431396\n",
      "110 0.2198755145072937\n",
      "120 0.38373830914497375\n",
      "130 0.44086790084838867\n",
      "140 0.27576011419296265\n",
      "150 0.24956780672073364\n",
      "160 0.350797563791275\n",
      "170 0.14812584221363068\n",
      "180 0.29077860713005066\n",
      "190 0.19548416137695312\n",
      "Validation loss: 0.943081259727478\n",
      "24 Selected hyperparameters: [4, 9, 0.7030715984639968] Estimated Loss: 0.13709512259568615 Real Loss: 0.943081259727478\n",
      "Model created with 16 heads, 8 dimensions per head, and 0.24413139407433482 dropout.\n",
      "0 63.784542083740234\n",
      "10 2.8841636180877686\n",
      "20 1.136942744255066\n",
      "30 2.0347068309783936\n",
      "40 0.6313064098358154\n",
      "50 1.622788906097412\n",
      "60 0.4850305914878845\n",
      "70 0.4316234290599823\n",
      "80 0.3080279529094696\n",
      "90 0.33640992641448975\n",
      "100 0.27664121985435486\n",
      "110 0.13392947614192963\n",
      "120 0.2478138655424118\n",
      "130 0.3077796697616577\n",
      "140 0.24449925124645233\n",
      "150 0.13048426806926727\n",
      "160 0.23907305300235748\n",
      "170 0.24082769453525543\n",
      "180 0.4129544198513031\n",
      "190 0.5601130723953247\n",
      "Validation loss: 1.1375350952148438\n",
      "25 Selected hyperparameters: [8, 16, 0.24413139407433482] Estimated Loss: 0.1415002742580814 Real Loss: 1.1375350952148438\n",
      "Model created with 5 heads, 4 dimensions per head, and 0.6857378008178746 dropout.\n",
      "0 5.89129638671875\n",
      "10 0.942221999168396\n",
      "20 0.43893641233444214\n",
      "30 0.606690526008606\n",
      "40 0.48323822021484375\n",
      "50 0.3101693093776703\n",
      "60 0.3771689236164093\n",
      "70 0.2468593716621399\n",
      "80 0.32726314663887024\n",
      "90 0.2629411220550537\n",
      "100 0.3026176691055298\n",
      "110 0.2008197009563446\n",
      "120 0.2994496524333954\n",
      "130 0.25488483905792236\n",
      "140 0.2530960738658905\n",
      "150 0.37829673290252686\n",
      "160 0.3319840431213379\n",
      "170 0.31564319133758545\n",
      "180 0.23804108798503876\n",
      "190 0.36313578486442566\n",
      "Validation loss: 0.8415619730949402\n",
      "26 Selected hyperparameters: [4, 5, 0.6857378008178746] Estimated Loss: 0.17511197203320636 Real Loss: 0.8415619730949402\n",
      "Model created with 8 heads, 16 dimensions per head, and 0.7648887886761243 dropout.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 36.888858795166016\n",
      "10 3.6707763671875\n",
      "20 2.540130376815796\n",
      "30 1.840556025505066\n",
      "40 0.9163954854011536\n",
      "50 0.8082001209259033\n",
      "60 0.7851095795631409\n",
      "70 0.7580246329307556\n",
      "80 0.5935381650924683\n",
      "90 0.7247492671012878\n",
      "100 0.656252920627594\n",
      "110 0.5185921788215637\n",
      "120 0.34991878271102905\n",
      "130 0.3129384219646454\n",
      "140 0.2907581925392151\n",
      "150 0.4961710572242737\n",
      "160 0.3765864074230194\n",
      "170 0.6616641879081726\n",
      "180 0.23846633732318878\n",
      "190 0.5442265272140503\n",
      "Validation loss: 1.0934500694274902\n",
      "27 Selected hyperparameters: [16, 8, 0.7648887886761243] Estimated Loss: 0.19639740531460176 Real Loss: 1.0934500694274902\n",
      "Model created with 4 heads, 10 dimensions per head, and 0.2147792227887877 dropout.\n",
      "0 8.722143173217773\n",
      "10 0.6688010692596436\n",
      "20 1.139418125152588\n",
      "30 0.3529220521450043\n",
      "40 1.0995802879333496\n",
      "50 0.21223461627960205\n",
      "60 0.17331203818321228\n",
      "70 0.1349109560251236\n",
      "80 0.23027543723583221\n",
      "90 0.34467625617980957\n",
      "100 0.1701975017786026\n",
      "110 0.11416415125131607\n",
      "120 0.1803189218044281\n",
      "130 0.31815698742866516\n",
      "140 0.24358513951301575\n",
      "150 0.14161106944084167\n",
      "160 0.2288840264081955\n",
      "170 0.12265294045209885\n",
      "180 0.18487980961799622\n",
      "190 0.2585919499397278\n",
      "Validation loss: 1.3403046131134033\n",
      "28 Selected hyperparameters: [10, 4, 0.2147792227887877] Estimated Loss: 0.1741742558883923 Real Loss: 1.3403046131134033\n",
      "Model created with 10 heads, 14 dimensions per head, and 0.690220974799326 dropout.\n",
      "0 21.895360946655273\n",
      "10 3.783209800720215\n",
      "20 1.4278318881988525\n",
      "30 1.4280356168746948\n",
      "40 1.6609840393066406\n",
      "50 0.840375542640686\n",
      "60 0.6067985892295837\n",
      "70 0.4324370324611664\n",
      "80 0.5487256050109863\n",
      "90 0.28493183851242065\n",
      "100 0.44241979718208313\n",
      "110 0.2058284431695938\n",
      "120 0.4685654640197754\n",
      "130 0.6780639886856079\n",
      "140 0.23934532701969147\n",
      "150 0.34767216444015503\n",
      "160 0.47821712493896484\n",
      "170 0.3930720388889313\n",
      "180 0.45534107089042664\n",
      "190 0.3352113366127014\n",
      "Validation loss: 1.094705581665039\n",
      "29 Selected hyperparameters: [14, 10, 0.690220974799326] Estimated Loss: 0.22571602845542846 Real Loss: 1.094705581665039\n",
      "Model created with 9 heads, 8 dimensions per head, and 0.534319979548012 dropout.\n",
      "0 13.136646270751953\n",
      "10 3.4719581604003906\n",
      "20 1.711590051651001\n",
      "30 0.5718615651130676\n",
      "40 0.18000738322734833\n",
      "50 0.5321118831634521\n",
      "60 0.38343533873558044\n",
      "70 0.35187986493110657\n",
      "80 0.5529292225837708\n",
      "90 0.27169328927993774\n",
      "100 0.6986318230628967\n",
      "110 0.29570356011390686\n",
      "120 0.17415578663349152\n",
      "130 0.18590058386325836\n",
      "140 0.43837276101112366\n",
      "150 0.36955708265304565\n",
      "160 0.25797316431999207\n",
      "170 0.22800809144973755\n",
      "180 0.35663914680480957\n",
      "190 0.21917299926280975\n",
      "Validation loss: 1.041788101196289\n",
      "30 Selected hyperparameters: [8, 9, 0.534319979548012] Estimated Loss: 0.22424868714830712 Real Loss: 1.041788101196289\n",
      "Model created with 3 heads, 14 dimensions per head, and 0.33127711431511364 dropout.\n",
      "0 7.608628273010254\n",
      "10 1.3786579370498657\n",
      "20 0.31311938166618347\n",
      "30 0.33108240365982056\n",
      "40 0.38447344303131104\n",
      "50 0.7331544160842896\n",
      "60 0.3114905059337616\n",
      "70 0.31614789366722107\n",
      "80 0.25877368450164795\n",
      "90 0.14286482334136963\n",
      "100 0.18042869865894318\n",
      "110 0.2170557826757431\n",
      "120 0.17989571392536163\n",
      "130 0.21128620207309723\n",
      "140 0.16126717627048492\n",
      "150 0.3191877603530884\n",
      "160 0.44332632422447205\n",
      "170 0.21864904463291168\n",
      "180 0.22983311116695404\n",
      "190 0.23426789045333862\n",
      "Validation loss: 1.010048270225525\n",
      "31 Selected hyperparameters: [14, 3, 0.33127711431511364] Estimated Loss: 0.23056499643737746 Real Loss: 1.010048270225525\n",
      "Model created with 1 heads, 12 dimensions per head, and 0.7020584440092194 dropout.\n",
      "0 4.159482002258301\n",
      "10 1.198790192604065\n",
      "20 0.6575303673744202\n",
      "30 0.37602078914642334\n",
      "40 0.6941302418708801\n",
      "50 0.5429552793502808\n",
      "60 0.463244765996933\n",
      "70 0.5462674498558044\n",
      "80 0.5271099805831909\n",
      "90 0.6266174912452698\n",
      "100 0.2735745906829834\n",
      "110 0.504811704158783\n",
      "120 0.44761237502098083\n",
      "130 0.4087289273738861\n",
      "140 0.4393278956413269\n",
      "150 0.6330495476722717\n",
      "160 0.5145927667617798\n",
      "170 0.4701758921146393\n",
      "180 0.5782262086868286\n",
      "190 0.5331521034240723\n",
      "Validation loss: 0.8257504105567932\n",
      "32 Selected hyperparameters: [12, 1, 0.7020584440092194] Estimated Loss: 0.25965576335707563 Real Loss: 0.8257504105567932\n",
      "Model created with 7 heads, 10 dimensions per head, and 0.7062247053805708 dropout.\n",
      "0 10.392533302307129\n",
      "10 2.0794119834899902\n",
      "20 2.055946111679077\n",
      "30 1.0342856645584106\n",
      "40 0.5546402931213379\n",
      "50 0.5813353657722473\n",
      "60 0.602479875087738\n",
      "70 0.4050181210041046\n",
      "80 0.3705404996871948\n",
      "90 0.48287874460220337\n",
      "100 0.31002429127693176\n",
      "110 0.8588705658912659\n",
      "120 0.396454781293869\n",
      "130 0.27431991696357727\n",
      "140 0.2644929885864258\n",
      "150 0.4423242509365082\n",
      "160 0.5522242784500122\n",
      "170 0.22464504837989807\n",
      "180 0.4469827115535736\n",
      "190 0.28394463658332825\n",
      "Validation loss: 0.8944666981697083\n",
      "33 Selected hyperparameters: [10, 7, 0.7062247053805708] Estimated Loss: 0.27349777628884736 Real Loss: 0.8944666981697083\n",
      "Model created with 16 heads, 4 dimensions per head, and 0.8574260949227357 dropout.\n",
      "0 15.328452110290527\n",
      "10 3.1086950302124023\n",
      "20 0.8874039649963379\n",
      "30 0.7490447759628296\n",
      "40 0.5875442624092102\n",
      "50 1.0441951751708984\n",
      "60 0.19664283096790314\n",
      "70 0.2928108274936676\n",
      "80 0.4511644244194031\n",
      "90 0.39754733443260193\n",
      "100 0.60561203956604\n",
      "110 0.56142258644104\n",
      "120 0.344474196434021\n",
      "130 0.35733500123023987\n",
      "140 0.29197612404823303\n",
      "150 0.3940986096858978\n",
      "160 0.2594376802444458\n",
      "170 0.24908173084259033\n",
      "180 0.41321754455566406\n",
      "190 0.46070611476898193\n",
      "Validation loss: 0.8950589895248413\n",
      "34 Selected hyperparameters: [4, 16, 0.8574260949227357] Estimated Loss: 0.24736778846177362 Real Loss: 0.8950589895248413\n",
      "Model created with 9 heads, 12 dimensions per head, and 0.003091180715640518 dropout.\n",
      "0 5.781435489654541\n",
      "10 2.3565762042999268\n",
      "20 2.237755298614502\n",
      "30 5.750883102416992\n",
      "40 0.8088357448577881\n",
      "50 0.9337703585624695\n",
      "60 1.5388556718826294\n",
      "70 0.3492092788219452\n",
      "80 0.24895012378692627\n",
      "90 0.27738264203071594\n",
      "100 0.22523462772369385\n",
      "110 0.16940870881080627\n",
      "120 0.12472677230834961\n",
      "130 1.387078046798706\n",
      "140 0.15393304824829102\n",
      "150 0.08952467143535614\n",
      "160 0.08342153578996658\n",
      "170 0.2411690056324005\n",
      "180 0.1364610344171524\n",
      "190 0.18854987621307373\n",
      "Validation loss: 0.9206328392028809\n",
      "35 Selected hyperparameters: [12, 9, 0.003091180715640518] Estimated Loss: 0.28851571668654263 Real Loss: 0.9206328392028809\n",
      "Model created with 13 heads, 12 dimensions per head, and 0.2364572707608361 dropout.\n",
      "0 107.31440734863281\n",
      "10 4.024783611297607\n",
      "20 2.0421159267425537\n",
      "30 1.7512481212615967\n",
      "40 1.3067469596862793\n",
      "50 1.2679022550582886\n",
      "60 1.046505331993103\n",
      "70 0.5828646421432495\n",
      "80 0.27262359857559204\n",
      "90 0.3638450503349304\n",
      "100 0.9414113759994507\n",
      "110 0.15858782827854156\n",
      "120 0.1888350546360016\n",
      "130 0.23645834624767303\n",
      "140 0.3806922733783722\n",
      "150 0.1537817418575287\n",
      "160 0.4334673285484314\n",
      "170 0.1618635207414627\n",
      "180 0.20470847189426422\n",
      "190 0.11746132373809814\n",
      "Validation loss: 0.8419309854507446\n",
      "36 Selected hyperparameters: [12, 13, 0.2364572707608361] Estimated Loss: 0.3014270050976172 Real Loss: 0.8419309854507446\n",
      "Model created with 12 heads, 6 dimensions per head, and 0.966422865705855 dropout.\n",
      "0 18.284467697143555\n",
      "10 6.118579864501953\n",
      "20 3.2587902545928955\n",
      "30 2.0794711112976074\n",
      "40 1.2503453493118286\n",
      "50 1.01557195186615\n",
      "60 0.8719308376312256\n",
      "70 1.4930284023284912\n",
      "80 1.4942066669464111\n",
      "90 1.2705016136169434\n",
      "100 1.2334822416305542\n",
      "110 0.9902341961860657\n",
      "120 1.4076659679412842\n",
      "130 1.9629297256469727\n",
      "140 1.7015206813812256\n",
      "150 2.4956986904144287\n",
      "160 1.5422999858856201\n",
      "170 1.5375934839248657\n",
      "180 1.5199424028396606\n",
      "190 1.3963106870651245\n",
      "Validation loss: 1.2538731098175049\n",
      "37 Selected hyperparameters: [6, 12, 0.966422865705855] Estimated Loss: 0.3144985213104458 Real Loss: 1.2538731098175049\n",
      "Model created with 12 heads, 10 dimensions per head, and 0.7764185707097665 dropout.\n",
      "0 30.402563095092773\n",
      "10 4.009749889373779\n",
      "20 1.6343913078308105\n",
      "30 1.1497682332992554\n",
      "40 1.0240951776504517\n",
      "50 0.8697391152381897\n",
      "60 0.5062804818153381\n",
      "70 0.6665439009666443\n",
      "80 0.4992283582687378\n",
      "90 0.8024787902832031\n",
      "100 0.6858454346656799\n",
      "110 0.6719210743904114\n",
      "120 0.5243822932243347\n",
      "130 0.6290541887283325\n",
      "140 0.29955360293388367\n",
      "150 0.792189359664917\n",
      "160 0.5660390853881836\n",
      "170 0.6878719329833984\n",
      "180 0.5532532930374146\n",
      "190 0.3922235369682312\n",
      "Validation loss: 0.9843543767929077\n",
      "38 Selected hyperparameters: [10, 12, 0.7764185707097665] Estimated Loss: 0.3367653442664227 Real Loss: 0.9843543767929077\n",
      "Model created with 3 heads, 16 dimensions per head, and 0.9222383707214354 dropout.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 12.780953407287598\n",
      "10 2.365168333053589\n",
      "20 1.8625540733337402\n",
      "30 1.087505578994751\n",
      "40 0.9817621111869812\n",
      "50 0.7740575671195984\n",
      "60 0.5136865377426147\n",
      "70 0.7420762777328491\n",
      "80 0.6497557759284973\n",
      "90 0.7729532122612\n",
      "100 0.6302874088287354\n",
      "110 0.4500232934951782\n",
      "120 0.560550332069397\n",
      "130 0.7096766829490662\n",
      "140 0.619707465171814\n",
      "150 0.853278398513794\n",
      "160 0.7283875942230225\n",
      "170 0.8159453868865967\n",
      "180 0.30607181787490845\n",
      "190 0.9318698048591614\n",
      "Validation loss: 1.8020912408828735\n",
      "39 Selected hyperparameters: [16, 3, 0.9222383707214354] Estimated Loss: 0.3894890765833131 Real Loss: 1.8020912408828735\n",
      "Model created with 16 heads, 14 dimensions per head, and 0.4917613828077194 dropout.\n",
      "0 290.5881652832031\n",
      "10 8.79041576385498\n",
      "20 3.3199498653411865\n",
      "30 3.9115593433380127\n",
      "40 2.5978105068206787\n",
      "50 6.177531719207764\n",
      "60 2.2225563526153564\n",
      "70 1.3890674114227295\n",
      "80 2.9516642093658447\n",
      "90 1.2557941675186157\n",
      "100 0.8023875951766968\n",
      "110 0.7473366260528564\n",
      "120 0.6282666325569153\n",
      "130 0.33577802777290344\n",
      "140 0.4261478781700134\n",
      "150 0.2794460952281952\n",
      "160 0.2874464690685272\n",
      "170 0.42599719762802124\n",
      "180 0.2959606647491455\n",
      "190 0.3520386219024658\n",
      "Validation loss: 1.3006752729415894\n",
      "40 Selected hyperparameters: [14, 16, 0.4917613828077194] Estimated Loss: 0.3633529540820056 Real Loss: 1.3006752729415894\n",
      "Model created with 14 heads, 8 dimensions per head, and 0.9601797264365948 dropout.\n",
      "0 17.606916427612305\n",
      "10 2.920848846435547\n",
      "20 0.8187951445579529\n",
      "30 1.166293978691101\n",
      "40 0.8736327886581421\n",
      "50 0.6924951672554016\n",
      "60 0.7214736342430115\n",
      "70 0.6726332306861877\n",
      "80 1.0266255140304565\n",
      "90 1.119104027748108\n",
      "100 0.45273441076278687\n",
      "110 0.5743487477302551\n",
      "120 1.052201271057129\n",
      "130 0.5295249223709106\n",
      "140 0.7591685652732849\n",
      "150 0.5674647092819214\n",
      "160 0.9286432266235352\n",
      "170 1.4178943634033203\n",
      "180 0.5485504269599915\n",
      "190 1.0095092058181763\n",
      "Validation loss: 1.4358303546905518\n",
      "41 Selected hyperparameters: [8, 14, 0.9601797264365948] Estimated Loss: 0.38365721919191303 Real Loss: 1.4358303546905518\n",
      "Model created with 16 heads, 10 dimensions per head, and 0.603483438273363 dropout.\n",
      "0 75.34835815429688\n",
      "10 4.663755893707275\n",
      "20 3.5245580673217773\n",
      "30 3.117840528488159\n",
      "40 1.2890292406082153\n",
      "50 0.9772658944129944\n",
      "60 0.7063150405883789\n",
      "70 0.5904086232185364\n",
      "80 0.4196736514568329\n",
      "90 0.30521926283836365\n",
      "100 0.27787521481513977\n",
      "110 0.2531634569168091\n",
      "120 0.33298948407173157\n",
      "130 0.7146434783935547\n",
      "140 0.3391369581222534\n",
      "150 0.2882806658744812\n",
      "160 0.3845132291316986\n",
      "170 0.4805409610271454\n",
      "180 0.3342501223087311\n",
      "190 0.23858915269374847\n",
      "Validation loss: 0.9970283508300781\n",
      "42 Selected hyperparameters: [10, 16, 0.603483438273363] Estimated Loss: 0.36779754839402207 Real Loss: 0.9970283508300781\n",
      "Model created with 9 heads, 2 dimensions per head, and 0.8922486213296985 dropout.\n",
      "0 6.3762922286987305\n",
      "10 1.3080953359603882\n",
      "20 0.8630327582359314\n",
      "30 0.896186113357544\n",
      "40 0.34825876355171204\n",
      "50 0.49976345896720886\n",
      "60 0.6254620552062988\n",
      "70 0.771527886390686\n",
      "80 0.27248257398605347\n",
      "90 0.5519586205482483\n",
      "100 0.22595232725143433\n",
      "110 0.49625924229621887\n",
      "120 0.38119348883628845\n",
      "130 0.4174526333808899\n",
      "140 0.3220542073249817\n",
      "150 0.5069157481193542\n",
      "160 0.31420964002609253\n",
      "170 0.3363528251647949\n",
      "180 0.3020799458026886\n",
      "190 0.5047572255134583\n",
      "Validation loss: 1.0529580116271973\n",
      "43 Selected hyperparameters: [2, 9, 0.8922486213296985] Estimated Loss: 0.43281952404477575 Real Loss: 1.0529580116271973\n",
      "Model created with 5 heads, 14 dimensions per head, and 0.4143515109720308 dropout.\n",
      "0 25.710294723510742\n",
      "10 1.7144701480865479\n",
      "20 1.099626064300537\n",
      "30 0.8451176881790161\n",
      "40 0.43932098150253296\n",
      "50 0.7683501839637756\n",
      "60 0.8138432502746582\n",
      "70 0.6082271337509155\n",
      "80 0.5474061369895935\n",
      "90 0.4314592480659485\n",
      "100 0.2446952611207962\n",
      "110 0.21437565982341766\n",
      "120 0.1730516403913498\n",
      "130 0.16549238562583923\n",
      "140 0.38090780377388\n",
      "150 0.56456059217453\n",
      "160 0.251960426568985\n",
      "170 0.3563426434993744\n",
      "180 0.459672749042511\n",
      "190 0.40248680114746094\n",
      "Validation loss: 1.183215618133545\n",
      "44 Selected hyperparameters: [14, 5, 0.4143515109720308] Estimated Loss: 0.4344995000504746 Real Loss: 1.183215618133545\n",
      "Model created with 7 heads, 4 dimensions per head, and 0.8911825638222481 dropout.\n",
      "0 11.884129524230957\n",
      "10 2.1857457160949707\n",
      "20 1.3159842491149902\n",
      "30 0.5769914388656616\n",
      "40 0.5521130561828613\n",
      "50 0.5500208735466003\n",
      "60 0.42650651931762695\n",
      "70 0.5622662305831909\n",
      "80 0.5059981942176819\n",
      "90 0.5601301193237305\n",
      "100 0.3336528241634369\n",
      "110 0.41805604100227356\n",
      "120 0.32380056381225586\n",
      "130 0.41554686427116394\n",
      "140 0.4965227246284485\n",
      "150 0.5269224047660828\n",
      "160 0.3717416822910309\n",
      "170 0.26988646388053894\n",
      "180 0.4890548288822174\n",
      "190 0.5833629369735718\n",
      "Validation loss: 1.169491171836853\n",
      "45 Selected hyperparameters: [4, 7, 0.8911825638222481] Estimated Loss: 0.3975545831962979 Real Loss: 1.169491171836853\n",
      "Model created with 12 heads, 4 dimensions per head, and 0.26736772059714553 dropout.\n",
      "0 5.8159027099609375\n",
      "10 2.1844635009765625\n",
      "20 0.6655554175376892\n",
      "30 0.7418996691703796\n",
      "40 1.0165669918060303\n",
      "50 0.21077948808670044\n",
      "60 0.5094661116600037\n",
      "70 0.11047204583883286\n",
      "80 0.18701167404651642\n",
      "90 0.33552780747413635\n",
      "100 0.2146846503019333\n",
      "110 0.33039024472236633\n",
      "120 0.15304553508758545\n",
      "130 0.041802261024713516\n",
      "140 0.24856241047382355\n",
      "150 0.33203479647636414\n",
      "160 0.2267780750989914\n",
      "170 0.3452184200286865\n",
      "180 0.10182415693998337\n",
      "190 0.07510187476873398\n",
      "Validation loss: 1.225831389427185\n",
      "46 Selected hyperparameters: [4, 12, 0.26736772059714553] Estimated Loss: 0.543749679798732 Real Loss: 1.225831389427185\n",
      "Model created with 14 heads, 4 dimensions per head, and 0.9517155132278139 dropout.\n",
      "0 11.910417556762695\n",
      "10 3.202336072921753\n",
      "20 2.7813754081726074\n",
      "30 1.2209022045135498\n",
      "40 0.7557156085968018\n",
      "50 0.7482045888900757\n",
      "60 0.9272063374519348\n",
      "70 0.577495276927948\n",
      "80 0.9121037721633911\n",
      "90 0.7437445521354675\n",
      "100 1.146239161491394\n",
      "110 1.5413851737976074\n",
      "120 0.6482025980949402\n",
      "130 0.8894465565681458\n",
      "140 0.3188433051109314\n",
      "150 0.5757828950881958\n",
      "160 1.0763201713562012\n",
      "170 0.8721536993980408\n",
      "180 0.7149420380592346\n",
      "190 1.5201098918914795\n",
      "Validation loss: 1.4287817478179932\n",
      "47 Selected hyperparameters: [4, 14, 0.9517155132278139] Estimated Loss: 0.4394904705962235 Real Loss: 1.4287817478179932\n",
      "Model created with 12 heads, 14 dimensions per head, and 0.6538827610380504 dropout.\n",
      "0 29.060163497924805\n",
      "10 5.211706161499023\n",
      "20 3.4706571102142334\n",
      "30 2.4037985801696777\n",
      "40 1.7168245315551758\n",
      "50 1.7559398412704468\n",
      "60 1.2537401914596558\n",
      "70 1.1371091604232788\n",
      "80 0.8802431225776672\n",
      "90 0.5505316853523254\n",
      "100 0.7040783166885376\n",
      "110 0.6244470477104187\n",
      "120 0.48271170258522034\n",
      "130 0.3485754132270813\n",
      "140 0.8455783724784851\n",
      "150 0.4797050356864929\n",
      "160 0.5286262035369873\n",
      "170 0.38570699095726013\n",
      "180 0.8022817373275757\n",
      "190 0.47090309858322144\n",
      "Validation loss: 0.9587013721466064\n",
      "48 Selected hyperparameters: [14, 12, 0.6538827610380504] Estimated Loss: 0.42060284379962604 Real Loss: 0.9587013721466064\n",
      "Model created with 1 heads, 14 dimensions per head, and 0.7543885431804931 dropout.\n",
      "0 4.829832553863525\n",
      "10 0.9891998171806335\n",
      "20 0.6104373931884766\n",
      "30 0.7466525435447693\n",
      "40 0.595371425151825\n",
      "50 0.5470500588417053\n",
      "60 0.7336230874061584\n",
      "70 0.6138996481895447\n",
      "80 0.44817811250686646\n",
      "90 0.5778830051422119\n",
      "100 0.5211747884750366\n",
      "110 0.6945960521697998\n",
      "120 0.8458619117736816\n",
      "130 0.2867763638496399\n",
      "140 0.434241384267807\n",
      "150 0.6039804816246033\n",
      "160 0.3498094379901886\n",
      "170 0.2855069041252136\n",
      "180 0.374728798866272\n",
      "190 0.6035106778144836\n",
      "Validation loss: 0.934658408164978\n",
      "49 Selected hyperparameters: [14, 1, 0.7543885431804931] Estimated Loss: 0.6240993575887163 Real Loss: 0.934658408164978\n",
      "Model created with 11 heads, 8 dimensions per head, and 0.8870742402390013 dropout.\n",
      "0 13.623068809509277\n",
      "10 4.137190341949463\n",
      "20 2.5233027935028076\n",
      "30 0.9051849246025085\n",
      "40 1.431227207183838\n",
      "50 0.9485027194023132\n",
      "60 0.46094274520874023\n",
      "70 0.5317580699920654\n",
      "80 0.606332004070282\n",
      "90 0.3406216502189636\n",
      "100 0.5863677263259888\n",
      "110 0.5396410822868347\n",
      "120 0.3564243018627167\n",
      "130 0.24663037061691284\n",
      "140 0.34976711869239807\n",
      "150 0.870803952217102\n",
      "160 0.30411404371261597\n",
      "170 0.8440147042274475\n",
      "180 0.4327864646911621\n",
      "190 0.32658082246780396\n",
      "Validation loss: 0.9562259912490845\n",
      "50 Selected hyperparameters: [8, 11, 0.8870742402390013] Estimated Loss: 0.5646643870420951 Real Loss: 0.9562259912490845\n",
      "Model created with 13 heads, 2 dimensions per head, and 0.9450540584956645 dropout.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 8.297420501708984\n",
      "10 2.5460684299468994\n",
      "20 1.1957906484603882\n",
      "30 0.7194837927818298\n",
      "40 0.48030391335487366\n",
      "50 0.38145238161087036\n",
      "60 0.4870482087135315\n",
      "70 0.4782376289367676\n",
      "80 0.49301356077194214\n",
      "90 0.5223873257637024\n",
      "100 0.4820299744606018\n",
      "110 0.8336557745933533\n",
      "120 0.3834737241268158\n",
      "130 0.2980536222457886\n",
      "140 0.34907597303390503\n",
      "150 0.5327146053314209\n",
      "160 0.6473811268806458\n",
      "170 0.3357948064804077\n",
      "180 0.29932349920272827\n",
      "190 0.4502626657485962\n",
      "Validation loss: 0.6943259835243225\n",
      "51 Selected hyperparameters: [2, 13, 0.9450540584956645] Estimated Loss: 0.451277020200628 Real Loss: 0.6943259835243225\n",
      "Model created with 5 heads, 2 dimensions per head, and 0.30545411954551527 dropout.\n",
      "0 4.989555835723877\n",
      "10 0.732159435749054\n",
      "20 0.5338594913482666\n",
      "30 0.43133023381233215\n",
      "40 0.3684835433959961\n",
      "50 0.43387913703918457\n",
      "60 0.5827975869178772\n",
      "70 0.46289682388305664\n",
      "80 0.5043671131134033\n",
      "90 0.31268957257270813\n",
      "100 0.4717077612876892\n",
      "110 0.33607229590415955\n",
      "120 0.3708060681819916\n",
      "130 0.25674110651016235\n",
      "140 0.3018400967121124\n",
      "150 0.4005107879638672\n",
      "160 0.29734140634536743\n",
      "170 0.4257611036300659\n",
      "180 0.44435229897499084\n",
      "190 0.40060457587242126\n",
      "Validation loss: 0.6810927391052246\n",
      "52 Selected hyperparameters: [2, 5, 0.30545411954551527] Estimated Loss: 0.6023398625864083 Real Loss: 0.6810927391052246\n",
      "Model created with 9 heads, 6 dimensions per head, and 0.015507024366253952 dropout.\n",
      "0 22.459177017211914\n",
      "10 0.5985010266304016\n",
      "20 0.4360879361629486\n",
      "30 0.7636986970901489\n",
      "40 0.24259354174137115\n",
      "50 0.20536789298057556\n",
      "60 0.09874805063009262\n",
      "70 0.066740021109581\n",
      "80 0.047295037657022476\n",
      "90 0.0929354727268219\n",
      "100 0.13656195998191833\n",
      "110 0.2254074513912201\n",
      "120 0.20051692426204681\n",
      "130 0.19099017977714539\n",
      "140 0.1513735055923462\n",
      "150 0.08511737734079361\n",
      "160 0.09659712761640549\n",
      "170 0.09003730863332748\n",
      "180 0.17420661449432373\n",
      "190 0.13266776502132416\n",
      "Validation loss: 0.9808796644210815\n",
      "53 Selected hyperparameters: [6, 9, 0.015507024366253952] Estimated Loss: 0.5437468496915034 Real Loss: 0.9808796644210815\n",
      "Model created with 10 heads, 10 dimensions per head, and 0.008193423747868245 dropout.\n",
      "0 36.83316421508789\n",
      "10 3.2623443603515625\n",
      "20 1.1909574270248413\n",
      "30 0.45571011304855347\n",
      "40 0.4115574359893799\n",
      "50 0.13703779876232147\n",
      "60 1.7422648668289185\n",
      "70 0.1422557681798935\n",
      "80 0.12698018550872803\n",
      "90 0.09624628722667694\n",
      "100 0.6890909075737\n",
      "110 0.09724721312522888\n",
      "120 0.08795057237148285\n",
      "130 0.3236117660999298\n",
      "140 0.2687307894229889\n",
      "150 0.05086546763777733\n",
      "160 0.1722157597541809\n",
      "170 0.06402714550495148\n",
      "180 0.08178658783435822\n",
      "190 0.10887658596038818\n",
      "Validation loss: 1.0093563795089722\n",
      "54 Selected hyperparameters: [10, 10, 0.008193423747868245] Estimated Loss: 0.6093446544804878 Real Loss: 1.0093563795089722\n",
      "Model created with 8 heads, 12 dimensions per head, and 0.8939096457686478 dropout.\n",
      "0 16.43740463256836\n",
      "10 8.41746997833252\n",
      "20 2.2472004890441895\n",
      "30 1.412699580192566\n",
      "40 0.8008167147636414\n",
      "50 0.7300078272819519\n",
      "60 0.7314061522483826\n",
      "70 0.4434375464916229\n",
      "80 0.7220124006271362\n",
      "90 0.4379863440990448\n",
      "100 0.5350181460380554\n",
      "110 0.8337242603302002\n",
      "120 0.3386046886444092\n",
      "130 0.4488474726676941\n",
      "140 0.3301687240600586\n",
      "150 0.2732281982898712\n",
      "160 0.27231135964393616\n",
      "170 0.3361867666244507\n",
      "180 0.29515835642814636\n",
      "190 0.5416402220726013\n",
      "Validation loss: 1.171015977859497\n",
      "55 Selected hyperparameters: [12, 8, 0.8939096457686478] Estimated Loss: 0.5515649764979544 Real Loss: 1.171015977859497\n",
      "Model created with 11 heads, 16 dimensions per head, and 0.16434857094712163 dropout.\n",
      "0 9.394255638122559\n",
      "10 2.9449281692504883\n",
      "20 2.052999258041382\n",
      "30 1.6497305631637573\n",
      "40 7.600214004516602\n",
      "50 1.842930793762207\n",
      "60 1.0459359884262085\n",
      "70 2.4461894035339355\n",
      "80 0.7204273343086243\n",
      "90 0.8951185345649719\n",
      "100 0.34205758571624756\n",
      "110 0.7635259032249451\n",
      "120 0.24571317434310913\n",
      "130 0.29336756467819214\n",
      "140 0.2391090840101242\n",
      "150 0.2564390003681183\n",
      "160 0.10104956477880478\n",
      "170 0.21506720781326294\n",
      "180 0.2155257612466812\n",
      "190 0.20903024077415466\n",
      "Validation loss: 0.9064209461212158\n",
      "56 Selected hyperparameters: [16, 11, 0.16434857094712163] Estimated Loss: 0.63494071224307 Real Loss: 0.9064209461212158\n",
      "Model created with 2 heads, 6 dimensions per head, and 0.9904131067945855 dropout.\n",
      "0 5.099508285522461\n",
      "10 2.002457857131958\n",
      "20 1.1091735363006592\n",
      "30 0.9743823409080505\n",
      "40 1.0025787353515625\n",
      "50 0.9226500988006592\n",
      "60 0.9315471053123474\n",
      "70 1.1522055864334106\n",
      "80 1.3075896501541138\n",
      "90 1.0274497270584106\n",
      "100 1.1909801959991455\n",
      "110 1.1303038597106934\n",
      "120 1.43922758102417\n",
      "130 1.371047854423523\n",
      "140 1.2184405326843262\n",
      "150 1.1609469652175903\n",
      "160 1.5980130434036255\n",
      "170 1.6647119522094727\n",
      "180 1.2253681421279907\n",
      "190 1.7844310998916626\n",
      "Validation loss: 1.1830278635025024\n",
      "57 Selected hyperparameters: [6, 2, 0.9904131067945855] Estimated Loss: 0.5870829483102649 Real Loss: 1.1830278635025024\n",
      "Model created with 1 heads, 8 dimensions per head, and 0.055149840592306876 dropout.\n",
      "0 3.4139230251312256\n",
      "10 0.9732998609542847\n",
      "20 0.9902434945106506\n",
      "30 0.6637367010116577\n",
      "40 0.756632387638092\n",
      "50 0.5782926678657532\n",
      "60 0.39996543526649475\n",
      "70 0.41928738355636597\n",
      "80 1.0197383165359497\n",
      "90 0.4486539661884308\n",
      "100 0.6960669755935669\n",
      "110 0.2647508978843689\n",
      "120 0.7076702117919922\n",
      "130 0.344373881816864\n",
      "140 0.4120250940322876\n",
      "150 0.4088747799396515\n",
      "160 0.3076009750366211\n",
      "170 0.4648098945617676\n",
      "180 0.6244773864746094\n",
      "190 0.5879912376403809\n",
      "Validation loss: 0.9142725467681885\n",
      "58 Selected hyperparameters: [8, 1, 0.055149840592306876] Estimated Loss: 0.533946255080858 Real Loss: 0.9142725467681885\n",
      "Model created with 5 heads, 2 dimensions per head, and 0.15898064179443205 dropout.\n",
      "0 5.0955891609191895\n",
      "10 1.522593379020691\n",
      "20 0.3735460937023163\n",
      "30 0.6560928821563721\n",
      "40 0.395234078168869\n",
      "50 0.5457148551940918\n",
      "60 0.4800671637058258\n",
      "70 0.3477661609649658\n",
      "80 0.5520879626274109\n",
      "90 0.3885754644870758\n",
      "100 0.3777720332145691\n",
      "110 0.2953028678894043\n",
      "120 0.37111353874206543\n",
      "130 0.29694145917892456\n",
      "140 0.27078503370285034\n",
      "150 0.27066874504089355\n",
      "160 0.37874144315719604\n",
      "170 0.3275388479232788\n",
      "180 0.33186882734298706\n",
      "190 0.376920610666275\n",
      "Validation loss: 0.7357608079910278\n",
      "59 Selected hyperparameters: [2, 5, 0.15898064179443205] Estimated Loss: 0.6530769144632947 Real Loss: 0.7357608079910278\n",
      "Model created with 6 heads, 2 dimensions per head, and 0.9855432070566343 dropout.\n",
      "0 2.965020179748535\n",
      "10 1.6328539848327637\n",
      "20 1.2125388383865356\n",
      "30 1.0567036867141724\n",
      "40 1.0611281394958496\n",
      "50 1.043182611465454\n",
      "60 0.8303304314613342\n",
      "70 1.2807332277297974\n",
      "80 1.2430487871170044\n",
      "90 1.1809288263320923\n",
      "100 1.0339035987854004\n",
      "110 1.357393503189087\n",
      "120 1.1297606229782104\n",
      "130 1.5528514385223389\n",
      "140 1.2170946598052979\n",
      "150 1.1392605304718018\n",
      "160 1.2537713050842285\n",
      "170 1.881595253944397\n",
      "180 1.2042101621627808\n",
      "190 1.5414719581604004\n",
      "Validation loss: 1.416864275932312\n",
      "60 Selected hyperparameters: [2, 6, 0.9855432070566343] Estimated Loss: 0.3310663358642121 Real Loss: 1.416864275932312\n",
      "Model created with 15 heads, 16 dimensions per head, and 0.26313040839539614 dropout.\n",
      "0 205.35829162597656\n",
      "10 5.86838960647583\n",
      "20 3.065889596939087\n",
      "30 5.651439666748047\n",
      "40 3.5969438552856445\n",
      "50 3.603813648223877\n",
      "60 1.9044818878173828\n",
      "70 1.6283894777297974\n",
      "80 0.5517396330833435\n",
      "90 0.9454051852226257\n",
      "100 0.5537493824958801\n",
      "110 0.41505059599876404\n",
      "120 1.179372787475586\n",
      "130 0.708687961101532\n",
      "140 0.7291685938835144\n",
      "150 0.2760196328163147\n",
      "160 0.2022911012172699\n",
      "170 0.5129348039627075\n",
      "180 0.2377810776233673\n",
      "190 0.22437641024589539\n",
      "Validation loss: 0.9711856842041016\n",
      "61 Selected hyperparameters: [16, 15, 0.26313040839539614] Estimated Loss: 0.6436723131587259 Real Loss: 0.9711856842041016\n",
      "Model created with 5 heads, 2 dimensions per head, and 0.47249847665781763 dropout.\n",
      "0 5.85886812210083\n",
      "10 1.2368687391281128\n",
      "20 0.5289321541786194\n",
      "30 0.5079636573791504\n",
      "40 0.5831884145736694\n",
      "50 0.32142359018325806\n",
      "60 0.29831334948539734\n",
      "70 0.3159467577934265\n",
      "80 0.37784871459007263\n",
      "90 0.3731514811515808\n",
      "100 0.4131218194961548\n",
      "110 0.3321177363395691\n",
      "120 0.44329890608787537\n",
      "130 0.468414306640625\n",
      "140 0.4272422790527344\n",
      "150 0.41043412685394287\n",
      "160 0.6757621169090271\n",
      "170 0.47339656949043274\n",
      "180 0.3083501160144806\n",
      "190 0.26864516735076904\n",
      "Validation loss: 1.0080699920654297\n",
      "62 Selected hyperparameters: [2, 5, 0.47249847665781763] Estimated Loss: 0.6224155251163346 Real Loss: 1.0080699920654297\n",
      "Model created with 4 heads, 2 dimensions per head, and 0.2888662355758036 dropout.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.860928535461426\n",
      "10 1.0749027729034424\n",
      "20 0.7964463233947754\n",
      "30 0.33631324768066406\n",
      "40 0.6824442148208618\n",
      "50 0.6805886626243591\n",
      "60 0.48324182629585266\n",
      "70 0.3467573821544647\n",
      "80 0.40106120705604553\n",
      "90 0.29651927947998047\n",
      "100 0.396157830953598\n",
      "110 0.4712308347225189\n",
      "120 0.4238556921482086\n",
      "130 0.33332711458206177\n",
      "140 0.46367940306663513\n",
      "150 0.3939841091632843\n",
      "160 0.30908676981925964\n",
      "170 0.26300159096717834\n",
      "180 0.34862250089645386\n",
      "190 0.30404603481292725\n",
      "Validation loss: 0.7846804261207581\n",
      "63 Selected hyperparameters: [2, 4, 0.2888662355758036] Estimated Loss: 0.06143984942127645 Real Loss: 0.7846804261207581\n",
      "Model created with 6 heads, 2 dimensions per head, and 0.4609343876409926 dropout.\n",
      "0 6.383755207061768\n",
      "10 0.8842459321022034\n",
      "20 1.7284427881240845\n",
      "30 0.6336366534233093\n",
      "40 0.3989292085170746\n",
      "50 0.4604189693927765\n",
      "60 0.6481823325157166\n",
      "70 0.3740968704223633\n",
      "80 0.21701587736606598\n",
      "90 0.20558799803256989\n",
      "100 0.3167508542537689\n",
      "110 0.3626943826675415\n",
      "120 0.1994396150112152\n",
      "130 0.21051621437072754\n",
      "140 0.24538373947143555\n",
      "150 0.2578144669532776\n",
      "160 0.2824469804763794\n",
      "170 0.27803707122802734\n",
      "180 0.38906365633010864\n",
      "190 0.274819016456604\n",
      "Validation loss: 0.8053024411201477\n",
      "64 Selected hyperparameters: [2, 6, 0.4609343876409926] Estimated Loss: -0.12566780998093918 Real Loss: 0.8053024411201477\n",
      "Model created with 7 heads, 2 dimensions per head, and 0.6411684767586358 dropout.\n",
      "0 4.872877597808838\n",
      "10 1.1628140211105347\n",
      "20 0.6452929973602295\n",
      "30 0.9365854263305664\n",
      "40 0.42658865451812744\n",
      "50 0.42379045486450195\n",
      "60 0.3481254279613495\n",
      "70 0.4408523440361023\n",
      "80 0.2454935759305954\n",
      "90 0.3497984707355499\n",
      "100 0.35957100987434387\n",
      "110 0.41969603300094604\n",
      "120 0.24231204390525818\n",
      "130 0.40612930059432983\n",
      "140 0.17006239295005798\n",
      "150 0.3459491431713104\n",
      "160 0.25314822793006897\n",
      "170 0.22588901221752167\n",
      "180 0.2007818967103958\n",
      "190 0.23681947588920593\n",
      "Validation loss: 0.8714324831962585\n",
      "65 Selected hyperparameters: [2, 7, 0.6411684767586358] Estimated Loss: 0.034128043053101464 Real Loss: 0.8714324831962585\n",
      "Model created with 4 heads, 4 dimensions per head, and 0.3116997645429236 dropout.\n",
      "0 4.460574626922607\n",
      "10 1.221834421157837\n",
      "20 0.45242440700531006\n",
      "30 0.3882491886615753\n",
      "40 0.4009380042552948\n",
      "50 0.3082483112812042\n",
      "60 0.8241797089576721\n",
      "70 0.27740275859832764\n",
      "80 0.18608509004116058\n",
      "90 0.3043416142463684\n",
      "100 0.29061567783355713\n",
      "110 0.27931153774261475\n",
      "120 0.21047261357307434\n",
      "130 0.29968002438545227\n",
      "140 0.2651054859161377\n",
      "150 0.37944504618644714\n",
      "160 0.3937007486820221\n",
      "170 0.30112168192863464\n",
      "180 0.4485919773578644\n",
      "190 0.14615757763385773\n",
      "Validation loss: 0.9250563979148865\n",
      "66 Selected hyperparameters: [4, 4, 0.3116997645429236] Estimated Loss: 0.5508118467529215 Real Loss: 0.9250563979148865\n",
      "Model created with 3 heads, 2 dimensions per head, and 0.9002970284450558 dropout.\n",
      "0 6.179864406585693\n",
      "10 1.228049635887146\n",
      "20 1.0288792848587036\n",
      "30 0.8517446517944336\n",
      "40 1.0156389474868774\n",
      "50 1.0128557682037354\n",
      "60 0.7811128497123718\n",
      "70 0.96014004945755\n",
      "80 0.7992081642150879\n",
      "90 0.8662676215171814\n",
      "100 0.9366111755371094\n",
      "110 0.6891992092132568\n",
      "120 0.5959967970848083\n",
      "130 0.5122041702270508\n",
      "140 0.5310875177383423\n",
      "150 1.02979576587677\n",
      "160 0.6609034538269043\n",
      "170 0.474012166261673\n",
      "180 0.525472104549408\n",
      "190 0.7290492653846741\n",
      "Validation loss: 0.7964814901351929\n",
      "67 Selected hyperparameters: [2, 3, 0.9002970284450558] Estimated Loss: -0.21943494537836727 Real Loss: 0.7964814901351929\n",
      "Model created with 1 heads, 4 dimensions per head, and 0.17764671483743533 dropout.\n",
      "0 5.627963542938232\n",
      "10 0.960098922252655\n",
      "20 0.7333039045333862\n",
      "30 0.9723222851753235\n",
      "40 0.5954245924949646\n",
      "50 0.8323699831962585\n",
      "60 1.061220407485962\n",
      "70 0.9230220317840576\n",
      "80 1.008730173110962\n",
      "90 1.1997644901275635\n",
      "100 0.9781805872917175\n",
      "110 0.9211293458938599\n",
      "120 1.0055968761444092\n",
      "130 0.8544784188270569\n",
      "140 0.864959716796875\n",
      "150 0.9712660908699036\n",
      "160 0.7442784905433655\n",
      "170 0.6497892737388611\n",
      "180 0.8847031593322754\n",
      "190 1.0888125896453857\n",
      "Validation loss: 0.9992352724075317\n",
      "68 Selected hyperparameters: [4, 1, 0.17764671483743533] Estimated Loss: 0.6177049043755084 Real Loss: 0.9992352724075317\n",
      "Model created with 12 heads, 8 dimensions per head, and 0.061701465050369664 dropout.\n",
      "0 6.895641803741455\n",
      "10 2.5124709606170654\n",
      "20 0.5485337376594543\n",
      "30 2.2963616847991943\n",
      "40 0.3273949921131134\n",
      "50 0.49415794014930725\n",
      "60 0.21245868504047394\n",
      "70 0.4196942150592804\n",
      "80 0.5522051453590393\n",
      "90 0.23890084028244019\n",
      "100 0.14513947069644928\n",
      "110 0.16202668845653534\n",
      "120 0.10194236040115356\n",
      "130 0.33046451210975647\n",
      "140 0.12322728335857391\n",
      "150 0.10691174119710922\n",
      "160 0.11871279031038284\n",
      "170 0.13237836956977844\n",
      "180 0.2087142914533615\n",
      "190 0.1080392450094223\n",
      "Validation loss: 0.956345796585083\n",
      "69 Selected hyperparameters: [8, 12, 0.061701465050369664] Estimated Loss: 0.603283083570256 Real Loss: 0.956345796585083\n",
      "Model created with 7 heads, 8 dimensions per head, and 0.2646088770932704 dropout.\n",
      "0 16.947032928466797\n",
      "10 0.9949116706848145\n",
      "20 0.4392884075641632\n",
      "30 0.31672200560569763\n",
      "40 0.7069401741027832\n",
      "50 0.2465328723192215\n",
      "60 0.3540910482406616\n",
      "70 0.1684758961200714\n",
      "80 0.11740480363368988\n",
      "90 0.11347325891256332\n",
      "100 0.18250152468681335\n",
      "110 0.4326244294643402\n",
      "120 0.17142389714717865\n",
      "130 0.20779664814472198\n",
      "140 0.24289268255233765\n",
      "150 0.16299846768379211\n",
      "160 0.21896694600582123\n",
      "170 0.1439523547887802\n",
      "180 0.24302442371845245\n",
      "190 0.22364139556884766\n",
      "Validation loss: 1.05324125289917\n",
      "70 Selected hyperparameters: [8, 7, 0.2646088770932704] Estimated Loss: 0.6113192853060299 Real Loss: 1.05324125289917\n",
      "Model created with 7 heads, 16 dimensions per head, and 0.1574027863277897 dropout.\n",
      "0 30.091917037963867\n",
      "10 3.4119088649749756\n",
      "20 1.677220344543457\n",
      "30 0.7027891278266907\n",
      "40 1.0474779605865479\n",
      "50 1.6192229986190796\n",
      "60 0.434714138507843\n",
      "70 0.39255860447883606\n",
      "80 0.4007492661476135\n",
      "90 0.3290576934814453\n",
      "100 0.20207113027572632\n",
      "110 0.27049925923347473\n",
      "120 0.2805481553077698\n",
      "130 0.13764892518520355\n",
      "140 0.20557741820812225\n",
      "150 0.30053460597991943\n",
      "160 0.20607762038707733\n",
      "170 0.23677581548690796\n",
      "180 0.2503966987133026\n",
      "190 0.07952572405338287\n",
      "Validation loss: 1.0832329988479614\n",
      "71 Selected hyperparameters: [16, 7, 0.1574027863277897] Estimated Loss: 0.6984668434919716 Real Loss: 1.0832329988479614\n",
      "Model created with 4 heads, 2 dimensions per head, and 0.45677146291997983 dropout.\n",
      "0 3.488288640975952\n",
      "10 0.7184961438179016\n",
      "20 0.7253905534744263\n",
      "30 0.6900771260261536\n",
      "40 0.5739122033119202\n",
      "50 0.5217969417572021\n",
      "60 0.5791643857955933\n",
      "70 0.46075576543807983\n",
      "80 0.618290901184082\n",
      "90 0.39053604006767273\n",
      "100 0.4372304379940033\n",
      "110 0.31315797567367554\n",
      "120 0.42014214396476746\n",
      "130 0.3480525016784668\n",
      "140 0.6349509954452515\n",
      "150 0.3265925645828247\n",
      "160 0.6399726271629333\n",
      "170 0.38883522152900696\n",
      "180 0.3462255597114563\n",
      "190 0.402987539768219\n",
      "Validation loss: 0.9782588481903076\n",
      "72 Selected hyperparameters: [2, 4, 0.45677146291997983] Estimated Loss: 0.6512676322043376 Real Loss: 0.9782588481903076\n",
      "Model created with 4 heads, 2 dimensions per head, and 0.9914658965553836 dropout.\n",
      "0 4.561295032501221\n",
      "10 1.2870782613754272\n",
      "20 1.1830079555511475\n",
      "30 1.3789762258529663\n",
      "40 1.8655128479003906\n",
      "50 1.1951351165771484\n",
      "60 1.2408316135406494\n",
      "70 0.7109267115592957\n",
      "80 1.3017890453338623\n",
      "90 0.7579073905944824\n",
      "100 0.6075089573860168\n",
      "110 0.6730698943138123\n",
      "120 1.1318626403808594\n",
      "130 1.064886450767517\n",
      "140 1.047675371170044\n",
      "150 0.9958679676055908\n",
      "160 1.2200655937194824\n",
      "170 0.832763671875\n",
      "180 0.909045398235321\n",
      "190 0.8036299347877502\n",
      "Validation loss: 1.048530101776123\n",
      "73 Selected hyperparameters: [2, 4, 0.9914658965553836] Estimated Loss: -0.38345879568515784 Real Loss: 1.048530101776123\n",
      "Model created with 14 heads, 12 dimensions per head, and 0.02972247573166098 dropout.\n",
      "0 216.2431182861328\n",
      "10 6.438523769378662\n",
      "20 1.885902762413025\n",
      "30 1.0770434141159058\n",
      "40 1.3456666469573975\n",
      "50 1.1911256313323975\n",
      "60 3.0068037509918213\n",
      "70 1.5615549087524414\n",
      "80 1.2087302207946777\n",
      "90 0.9100000262260437\n",
      "100 0.35775020718574524\n",
      "110 0.22484202682971954\n",
      "120 0.4874611794948578\n",
      "130 0.332293838262558\n",
      "140 0.502866268157959\n",
      "150 0.5517932772636414\n",
      "160 0.20786960422992706\n",
      "170 0.22186017036437988\n",
      "180 0.28751999139785767\n",
      "190 0.12787005305290222\n",
      "Validation loss: 1.6620241403579712\n",
      "74 Selected hyperparameters: [12, 14, 0.02972247573166098] Estimated Loss: 0.6622583514135627 Real Loss: 1.6620241403579712\n",
      "Model created with 5 heads, 12 dimensions per head, and 0.017983617992930134 dropout.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6.1639204025268555\n",
      "10 1.4762659072875977\n",
      "20 3.7561607360839844\n",
      "30 0.31341132521629333\n",
      "40 0.2349354475736618\n",
      "50 0.5315492153167725\n",
      "60 0.1440255343914032\n",
      "70 0.1456526666879654\n",
      "80 0.4254378378391266\n",
      "90 0.09118969738483429\n",
      "100 0.16137443482875824\n",
      "110 0.055021025240421295\n",
      "120 0.17782281339168549\n",
      "130 0.12983030080795288\n",
      "140 0.1970740705728531\n",
      "150 0.1373758763074875\n",
      "160 0.16274577379226685\n",
      "170 0.26136624813079834\n",
      "180 0.20576173067092896\n",
      "190 0.14552633464336395\n",
      "Validation loss: 1.099356770515442\n",
      "75 Selected hyperparameters: [12, 5, 0.017983617992930134] Estimated Loss: 0.6376806921137441 Real Loss: 1.099356770515442\n",
      "Model created with 5 heads, 2 dimensions per head, and 0.26702229409893474 dropout.\n",
      "0 6.571736812591553\n",
      "10 0.7521569728851318\n",
      "20 0.5461207628250122\n",
      "30 0.4513630270957947\n",
      "40 0.37478893995285034\n",
      "50 0.3263038992881775\n",
      "60 0.2664489448070526\n",
      "70 0.33168870210647583\n",
      "80 0.30141332745552063\n",
      "90 0.1671837717294693\n",
      "100 0.31480586528778076\n",
      "110 0.2580408751964569\n",
      "120 0.2929043471813202\n",
      "130 0.3058956563472748\n",
      "140 0.401879221200943\n",
      "150 0.295184463262558\n",
      "160 0.27932071685791016\n",
      "170 0.3015269637107849\n",
      "180 0.28152111172676086\n",
      "190 0.17575110495090485\n",
      "Validation loss: 0.932144045829773\n",
      "76 Selected hyperparameters: [2, 5, 0.26702229409893474] Estimated Loss: 0.6677910296509708 Real Loss: 0.932144045829773\n",
      "Model created with 6 heads, 2 dimensions per head, and 0.48332228004052014 dropout.\n",
      "0 5.73443078994751\n",
      "10 0.8172749280929565\n",
      "20 0.6856235265731812\n",
      "30 0.6495189070701599\n",
      "40 0.2771156132221222\n",
      "50 0.2660394310951233\n",
      "60 0.4580148458480835\n",
      "70 0.3157103657722473\n",
      "80 0.2644015848636627\n",
      "90 0.3947848081588745\n",
      "100 0.19289445877075195\n",
      "110 0.1735435575246811\n",
      "120 0.5835456848144531\n",
      "130 0.31138062477111816\n",
      "140 0.1792643964290619\n",
      "150 0.18251469731330872\n",
      "160 0.23576682806015015\n",
      "170 0.18828986585140228\n",
      "180 0.25282007455825806\n",
      "190 0.17004217207431793\n",
      "Validation loss: 0.9425585269927979\n",
      "77 Selected hyperparameters: [2, 6, 0.48332228004052014] Estimated Loss: -0.9648328688344918 Real Loss: 0.9425585269927979\n",
      "Model created with 10 heads, 4 dimensions per head, and 0.4842058735236383 dropout.\n",
      "0 11.088942527770996\n",
      "10 1.857883334159851\n",
      "20 0.8133664727210999\n",
      "30 0.783104658126831\n",
      "40 0.48265188932418823\n",
      "50 0.4287175238132477\n",
      "60 0.20291292667388916\n",
      "70 0.3106818199157715\n",
      "80 0.17239254713058472\n",
      "90 0.15299472212791443\n",
      "100 0.20198214054107666\n",
      "110 0.44852331280708313\n",
      "120 0.16680584847927094\n",
      "130 0.16916429996490479\n",
      "140 0.272827684879303\n",
      "150 0.2657213807106018\n",
      "160 0.229207843542099\n",
      "170 0.15715044736862183\n",
      "180 0.25596919655799866\n",
      "190 0.22445040941238403\n",
      "Validation loss: 1.0693845748901367\n",
      "78 Selected hyperparameters: [4, 10, 0.4842058735236383] Estimated Loss: 0.32002656139172503 Real Loss: 1.0693845748901367\n",
      "Model created with 7 heads, 2 dimensions per head, and 0.7017468542820589 dropout.\n",
      "0 4.92324161529541\n",
      "10 1.1072701215744019\n",
      "20 0.7009940147399902\n",
      "30 0.36763596534729004\n",
      "40 0.5184071660041809\n",
      "50 0.38453349471092224\n",
      "60 0.2949991822242737\n",
      "70 0.3707657754421234\n",
      "80 0.27346092462539673\n",
      "90 0.2649182677268982\n",
      "100 0.4282177686691284\n",
      "110 0.35161370038986206\n",
      "120 0.3279067873954773\n",
      "130 0.436757355928421\n",
      "140 0.28247594833374023\n",
      "150 0.4548053443431854\n",
      "160 0.2799872159957886\n",
      "170 0.3328739106655121\n",
      "180 0.20028920471668243\n",
      "190 0.21076025068759918\n",
      "Validation loss: 0.8973147869110107\n",
      "79 Selected hyperparameters: [2, 7, 0.7017468542820589] Estimated Loss: -4.72317403586203 Real Loss: 0.8973147869110107\n",
      "Model created with 3 heads, 2 dimensions per head, and 0.964221032594628 dropout.\n",
      "0 6.452979564666748\n",
      "10 1.6397109031677246\n",
      "20 1.1884814500808716\n",
      "30 0.7610934376716614\n",
      "40 1.0312467813491821\n",
      "50 0.7754670977592468\n",
      "60 1.098812460899353\n",
      "70 0.9557574987411499\n",
      "80 0.8646076917648315\n",
      "90 0.7223932147026062\n",
      "100 0.9566762447357178\n",
      "110 0.6151515245437622\n",
      "120 0.6319833397865295\n",
      "130 0.6610763072967529\n",
      "140 0.5807162523269653\n",
      "150 0.6905116438865662\n",
      "160 0.6861060261726379\n",
      "170 0.689570963382721\n",
      "180 0.5182440876960754\n",
      "190 0.5426348447799683\n",
      "Validation loss: 1.0661951303482056\n",
      "80 Selected hyperparameters: [2, 3, 0.964221032594628] Estimated Loss: -7.774321344433702 Real Loss: 1.0661951303482056\n",
      "Model created with 5 heads, 4 dimensions per head, and 0.5706178602152919 dropout.\n",
      "0 6.001552104949951\n",
      "10 1.4797483682632446\n",
      "20 0.4836518466472626\n",
      "30 0.9351269006729126\n",
      "40 0.5424299240112305\n",
      "50 0.27382969856262207\n",
      "60 0.2889506220817566\n",
      "70 0.1416103094816208\n",
      "80 0.3838519752025604\n",
      "90 0.44301557540893555\n",
      "100 0.39434143900871277\n",
      "110 0.23050342500209808\n",
      "120 0.32048240303993225\n",
      "130 0.25667673349380493\n",
      "140 0.2075088918209076\n",
      "150 0.33182623982429504\n",
      "160 0.18256302177906036\n",
      "170 0.2924531102180481\n",
      "180 0.17435769736766815\n",
      "190 0.32401275634765625\n",
      "Validation loss: 1.056537389755249\n",
      "81 Selected hyperparameters: [4, 5, 0.5706178602152919] Estimated Loss: -0.3191514230929897 Real Loss: 1.056537389755249\n",
      "Model created with 2 heads, 2 dimensions per head, and 0.19529703004854226 dropout.\n",
      "0 5.247991561889648\n",
      "10 2.1482222080230713\n",
      "20 1.4372738599777222\n",
      "30 1.529264211654663\n",
      "40 0.8018386363983154\n",
      "50 0.7951878309249878\n",
      "60 0.7540536522865295\n",
      "70 0.9764024615287781\n",
      "80 0.7107567191123962\n",
      "90 0.7021440863609314\n",
      "100 0.8326827883720398\n",
      "110 0.3360418677330017\n",
      "120 1.012967586517334\n",
      "130 0.4548253118991852\n",
      "140 0.721055805683136\n",
      "150 1.2757488489151\n",
      "160 0.9224015474319458\n",
      "170 0.8581263422966003\n",
      "180 0.6886323690414429\n",
      "190 0.6481273770332336\n",
      "Validation loss: 1.1758396625518799\n",
      "82 Selected hyperparameters: [2, 2, 0.19529703004854226] Estimated Loss: -41.564907462496194 Real Loss: 1.1758396625518799\n",
      "Model created with 4 heads, 2 dimensions per head, and 0.01573269788837295 dropout.\n",
      "0 3.0977163314819336\n",
      "10 0.7301703691482544\n",
      "20 0.5496467351913452\n",
      "30 0.41462352871894836\n",
      "40 0.4064370095729828\n",
      "50 0.39088448882102966\n",
      "60 0.24295181035995483\n",
      "70 0.42980635166168213\n",
      "80 0.33856600522994995\n",
      "90 0.3231358528137207\n",
      "100 0.17319993674755096\n",
      "110 0.2964414358139038\n",
      "120 0.4875624179840088\n",
      "130 0.3054599463939667\n",
      "140 0.1822899729013443\n",
      "150 0.31449565291404724\n",
      "160 0.17885509133338928\n",
      "170 0.26177385449409485\n",
      "180 0.2809593677520752\n",
      "190 0.2882532775402069\n",
      "Validation loss: 0.8479682803153992\n",
      "83 Selected hyperparameters: [2, 4, 0.01573269788837295] Estimated Loss: -6.214963784615975 Real Loss: 0.8479682803153992\n",
      "Model created with 6 heads, 2 dimensions per head, and 0.1370677407485027 dropout.\n",
      "0 4.028450965881348\n",
      "10 0.831331729888916\n",
      "20 0.5031649470329285\n",
      "30 0.35089433193206787\n",
      "40 0.2621002793312073\n",
      "50 0.2977628707885742\n",
      "60 0.4645853638648987\n",
      "70 0.2685561180114746\n",
      "80 0.3214206397533417\n",
      "90 0.25520816445350647\n",
      "100 0.3320225775241852\n",
      "110 0.1651933491230011\n",
      "120 0.44199228286743164\n",
      "130 0.23904237151145935\n",
      "140 0.21517245471477509\n",
      "150 0.22285303473472595\n",
      "160 0.26367881894111633\n",
      "170 0.31383877992630005\n",
      "180 0.19553522765636444\n",
      "190 0.32280686497688293\n",
      "Validation loss: 0.9012595415115356\n",
      "84 Selected hyperparameters: [2, 6, 0.1370677407485027] Estimated Loss: -16.113883672398515 Real Loss: 0.9012595415115356\n",
      "Model created with 3 heads, 2 dimensions per head, and 0.34023324604708804 dropout.\n",
      "0 3.9786980152130127\n",
      "10 1.4821410179138184\n",
      "20 1.497969388961792\n",
      "30 0.8509328961372375\n",
      "40 0.6306344270706177\n",
      "50 0.9061713814735413\n",
      "60 0.47103360295295715\n",
      "70 0.8010697960853577\n",
      "80 0.7056897282600403\n",
      "90 0.6014025211334229\n",
      "100 0.5423073768615723\n",
      "110 0.49657076597213745\n",
      "120 0.48676201701164246\n",
      "130 0.5818573832511902\n",
      "140 0.3362903892993927\n",
      "150 0.3373374044895172\n",
      "160 0.5162488222122192\n",
      "170 0.40594637393951416\n",
      "180 0.3857937455177307\n",
      "190 0.510208785533905\n",
      "Validation loss: 1.0079152584075928\n",
      "85 Selected hyperparameters: [2, 3, 0.34023324604708804] Estimated Loss: -36.7062734507781 Real Loss: 1.0079152584075928\n",
      "Model created with 4 heads, 2 dimensions per head, and 0.14935460102436138 dropout.\n",
      "0 5.626298427581787\n",
      "10 0.9793021082878113\n",
      "20 0.9012212753295898\n",
      "30 0.4882033169269562\n",
      "40 0.5636699795722961\n",
      "50 0.3140179514884949\n",
      "60 0.6550532579421997\n",
      "70 0.3894859552383423\n",
      "80 0.6088178157806396\n",
      "90 0.493608295917511\n",
      "100 0.4297511875629425\n",
      "110 0.4856933355331421\n",
      "120 0.32714900374412537\n",
      "130 0.2520592510700226\n",
      "140 0.3871428668498993\n",
      "150 0.2107003629207611\n",
      "160 0.3587445020675659\n",
      "170 0.5347409844398499\n",
      "180 0.6043928265571594\n",
      "190 0.3428462743759155\n",
      "Validation loss: 0.9487902522087097\n",
      "86 Selected hyperparameters: [2, 4, 0.14935460102436138] Estimated Loss: 0.6297617213567719 Real Loss: 0.9487902522087097\n",
      "Model created with 3 heads, 2 dimensions per head, and 0.7144976435964276 dropout.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6.555551052093506\n",
      "10 1.23695707321167\n",
      "20 1.2423465251922607\n",
      "30 0.594635546207428\n",
      "40 0.8892114162445068\n",
      "50 0.7918274402618408\n",
      "60 0.6462154388427734\n",
      "70 0.773669421672821\n",
      "80 0.7102941274642944\n",
      "90 0.7570218443870544\n",
      "100 0.4128968417644501\n",
      "110 0.801059365272522\n",
      "120 0.843647837638855\n",
      "130 0.6257211565971375\n",
      "140 0.612185537815094\n",
      "150 0.8797995448112488\n",
      "160 0.7615813612937927\n",
      "170 0.7575874328613281\n",
      "180 0.6027777791023254\n",
      "190 0.5723839998245239\n",
      "Validation loss: 0.8238431811332703\n",
      "87 Selected hyperparameters: [2, 3, 0.7144976435964276] Estimated Loss: 0.12957160593941808 Real Loss: 0.8238431811332703\n",
      "Model created with 7 heads, 2 dimensions per head, and 0.06729310762183116 dropout.\n",
      "0 6.072783946990967\n",
      "10 0.5582147240638733\n",
      "20 0.44293567538261414\n",
      "30 0.3552539348602295\n",
      "40 0.22387370467185974\n",
      "50 0.3315199017524719\n",
      "60 0.2979641258716583\n",
      "70 0.15673112869262695\n",
      "80 0.10998483002185822\n",
      "90 0.17559988796710968\n",
      "100 0.2243058681488037\n",
      "110 0.20325277745723724\n",
      "120 0.31368014216423035\n",
      "130 0.16062253713607788\n",
      "140 0.10715112090110779\n",
      "150 0.28752636909484863\n",
      "160 0.18664884567260742\n",
      "170 0.20347018539905548\n",
      "180 0.19422592222690582\n",
      "190 0.2503177523612976\n",
      "Validation loss: 0.8766571283340454\n",
      "88 Selected hyperparameters: [2, 7, 0.06729310762183116] Estimated Loss: 0.45447593691642396 Real Loss: 0.8766571283340454\n",
      "Model created with 7 heads, 2 dimensions per head, and 0.18824133742635873 dropout.\n",
      "0 2.4703290462493896\n",
      "10 0.9326168298721313\n",
      "20 0.5799061059951782\n",
      "30 0.4036482870578766\n",
      "40 0.3590248227119446\n",
      "50 0.39574792981147766\n",
      "60 0.3260469138622284\n",
      "70 0.3147595226764679\n",
      "80 0.331024706363678\n",
      "90 0.6557238101959229\n",
      "100 0.24438561499118805\n",
      "110 0.21928919851779938\n",
      "120 0.23698152601718903\n",
      "130 0.23159758746623993\n",
      "140 0.22677120566368103\n",
      "150 0.26073452830314636\n",
      "160 0.288778156042099\n",
      "170 0.3097195029258728\n",
      "180 0.23703651130199432\n",
      "190 0.21496623754501343\n",
      "Validation loss: 0.8820387125015259\n",
      "89 Selected hyperparameters: [2, 7, 0.18824133742635873] Estimated Loss: 0.39704037382034585 Real Loss: 0.8820387125015259\n",
      "Model created with 2 heads, 2 dimensions per head, and 0.31679984847196874 dropout.\n",
      "0 6.7380475997924805\n",
      "10 1.5430171489715576\n",
      "20 1.9676939249038696\n",
      "30 1.0016210079193115\n",
      "40 0.8597584962844849\n",
      "50 0.9171993136405945\n",
      "60 0.5663179159164429\n",
      "70 0.7043213844299316\n",
      "80 0.7352533340454102\n",
      "90 0.9119126796722412\n",
      "100 1.0009608268737793\n",
      "110 1.1438508033752441\n",
      "120 0.7877792119979858\n",
      "130 1.0373739004135132\n",
      "140 0.9230713844299316\n",
      "150 0.8004805445671082\n",
      "160 0.7512850165367126\n",
      "170 0.7478909492492676\n",
      "180 0.5260584950447083\n",
      "190 0.7005860805511475\n",
      "Validation loss: 0.8473331928253174\n",
      "90 Selected hyperparameters: [2, 2, 0.31679984847196874] Estimated Loss: -2.1751027614809573 Real Loss: 0.8473331928253174\n",
      "Model created with 8 heads, 2 dimensions per head, and 0.4143966459533539 dropout.\n",
      "0 4.257128715515137\n",
      "10 0.6295294165611267\n",
      "20 0.5268010497093201\n",
      "30 0.4926167130470276\n",
      "40 0.4066242575645447\n",
      "50 0.21894897520542145\n",
      "60 0.3020617961883545\n",
      "70 0.2979374825954437\n",
      "80 0.48258110880851746\n",
      "90 0.1207641214132309\n",
      "100 0.1768098771572113\n",
      "110 0.3001086115837097\n",
      "120 0.25096938014030457\n",
      "130 0.1454450637102127\n",
      "140 0.31331056356430054\n",
      "150 0.767092764377594\n",
      "160 0.31333884596824646\n",
      "170 0.2590327858924866\n",
      "180 0.31424185633659363\n",
      "190 0.20175230503082275\n",
      "Validation loss: 0.8311055898666382\n",
      "91 Selected hyperparameters: [2, 8, 0.4143966459533539] Estimated Loss: -1.4933430891251191 Real Loss: 0.8311055898666382\n",
      "Model created with 5 heads, 2 dimensions per head, and 0.13533516125121292 dropout.\n",
      "0 4.959949493408203\n",
      "10 0.7626305818557739\n",
      "20 0.5702134370803833\n",
      "30 0.3496590256690979\n",
      "40 0.41624215245246887\n",
      "50 0.5430421233177185\n",
      "60 0.4350551962852478\n",
      "70 0.22346694767475128\n",
      "80 0.28770726919174194\n",
      "90 0.19825218617916107\n",
      "100 0.314020037651062\n",
      "110 0.2029888778924942\n",
      "120 0.35943108797073364\n",
      "130 0.29361313581466675\n",
      "140 0.2133609652519226\n",
      "150 0.1571231186389923\n",
      "160 0.3057153522968292\n",
      "170 0.4337834119796753\n",
      "180 0.21120205521583557\n",
      "190 0.19103170931339264\n",
      "Validation loss: 1.0726311206817627\n",
      "92 Selected hyperparameters: [2, 5, 0.13533516125121292] Estimated Loss: 0.33133008796721697 Real Loss: 1.0726311206817627\n",
      "Model created with 2 heads, 2 dimensions per head, and 0.5040040357900029 dropout.\n",
      "0 4.17775821685791\n",
      "10 1.2865573167800903\n",
      "20 1.363587737083435\n",
      "30 1.1622068881988525\n",
      "40 1.4255138635635376\n",
      "50 1.1112372875213623\n",
      "60 1.021689772605896\n",
      "70 0.8742882013320923\n",
      "80 1.1238582134246826\n",
      "90 0.780794620513916\n",
      "100 0.43779778480529785\n",
      "110 0.35906368494033813\n",
      "120 0.6937917470932007\n",
      "130 0.6862785220146179\n",
      "140 0.7071551084518433\n",
      "150 0.6600021123886108\n",
      "160 0.7376212477684021\n",
      "170 0.774219274520874\n",
      "180 0.9371554255485535\n",
      "190 0.7604143023490906\n",
      "Validation loss: 0.9802148342132568\n",
      "93 Selected hyperparameters: [2, 2, 0.5040040357900029] Estimated Loss: -5.608889956027269 Real Loss: 0.9802148342132568\n",
      "Model created with 2 heads, 2 dimensions per head, and 0.13785970691858263 dropout.\n",
      "0 6.49893856048584\n",
      "10 1.8986209630966187\n",
      "20 1.3284316062927246\n",
      "30 1.160149335861206\n",
      "40 1.1229766607284546\n",
      "50 0.8978273272514343\n",
      "60 0.5349725484848022\n",
      "70 0.8978317975997925\n",
      "80 0.5481694936752319\n",
      "90 0.6835249066352844\n",
      "100 0.9487006664276123\n",
      "110 0.7781383395195007\n",
      "120 0.42862552404403687\n",
      "130 0.8092328310012817\n",
      "140 0.4636107087135315\n",
      "150 0.39420828223228455\n",
      "160 0.3776779770851135\n",
      "170 0.7481988668441772\n",
      "180 0.48898762464523315\n",
      "190 0.3274203836917877\n",
      "Validation loss: 0.9576262831687927\n",
      "94 Selected hyperparameters: [2, 2, 0.13785970691858263] Estimated Loss: -0.8519411105662584 Real Loss: 0.9576262831687927\n",
      "Model created with 6 heads, 2 dimensions per head, and 0.2602878872889929 dropout.\n",
      "0 5.753861427307129\n",
      "10 1.0909496545791626\n",
      "20 0.37197184562683105\n",
      "30 0.2922936975955963\n",
      "40 0.44691359996795654\n",
      "50 0.3659352660179138\n",
      "60 0.39394986629486084\n",
      "70 0.5878808498382568\n",
      "80 0.27719590067863464\n",
      "90 0.3261476159095764\n",
      "100 0.18577878177165985\n",
      "110 0.29622527956962585\n",
      "120 0.30007830262184143\n",
      "130 0.39395979046821594\n",
      "140 0.2323675900697708\n",
      "150 0.14905014634132385\n",
      "160 0.14333684742450714\n",
      "170 0.31861570477485657\n",
      "180 0.15570487082004547\n",
      "190 0.16042327880859375\n",
      "Validation loss: 0.680753231048584\n",
      "95 Selected hyperparameters: [2, 6, 0.2602878872889929] Estimated Loss: -4.036924242973328 Real Loss: 0.680753231048584\n",
      "Model created with 5 heads, 2 dimensions per head, and 0.3898129911285033 dropout.\n",
      "0 6.580451011657715\n",
      "10 0.6153388023376465\n",
      "20 0.9071553945541382\n",
      "30 0.7279289960861206\n",
      "40 0.513156533241272\n",
      "50 0.3252372443675995\n",
      "60 0.4346912205219269\n",
      "70 0.30957508087158203\n",
      "80 0.6037505865097046\n",
      "90 0.2058638632297516\n",
      "100 0.5495872497558594\n",
      "110 0.2751730978488922\n",
      "120 0.3708269000053406\n",
      "130 0.24587297439575195\n",
      "140 0.21782316267490387\n",
      "150 0.456852525472641\n",
      "160 0.341444730758667\n",
      "170 0.26044607162475586\n",
      "180 0.33865123987197876\n",
      "190 0.2750885784626007\n",
      "Validation loss: 0.8921850919723511\n",
      "96 Selected hyperparameters: [2, 5, 0.3898129911285033] Estimated Loss: 0.401553750038147 Real Loss: 0.8921850919723511\n",
      "Model created with 3 heads, 2 dimensions per head, and 0.03374556484546487 dropout.\n",
      "0 3.7041103839874268\n",
      "10 1.3390475511550903\n",
      "20 0.58038729429245\n",
      "30 0.6341304183006287\n",
      "40 0.382889062166214\n",
      "50 0.5328677892684937\n",
      "60 1.2117048501968384\n",
      "70 0.5329732894897461\n",
      "80 0.5175572633743286\n",
      "90 0.37365177273750305\n",
      "100 0.4256768226623535\n",
      "110 0.5916011333465576\n",
      "120 0.4822571277618408\n",
      "130 0.304337739944458\n",
      "140 0.5035566687583923\n",
      "150 0.49232229590415955\n",
      "160 0.2896081209182739\n",
      "170 0.25942593812942505\n",
      "180 0.2203378677368164\n",
      "190 0.34291496872901917\n",
      "Validation loss: 0.9829610586166382\n",
      "97 Selected hyperparameters: [2, 3, 0.03374556484546487] Estimated Loss: -10.341466218233109 Real Loss: 0.9829610586166382\n",
      "Model created with 4 heads, 4 dimensions per head, and 0.581319382743778 dropout.\n",
      "0 4.806389331817627\n",
      "10 1.2327872514724731\n",
      "20 0.5049722194671631\n",
      "30 0.5384312868118286\n",
      "40 0.6412897706031799\n",
      "50 0.5098786354064941\n",
      "60 0.2679138481616974\n",
      "70 0.4361899793148041\n",
      "80 0.3758338391780853\n",
      "90 0.5054656267166138\n",
      "100 0.43645811080932617\n",
      "110 0.5360101461410522\n",
      "120 0.2285407930612564\n",
      "130 0.25617295503616333\n",
      "140 0.32643431425094604\n",
      "150 0.29977700114250183\n",
      "160 0.3075728714466095\n",
      "170 0.37020304799079895\n",
      "180 0.4013020396232605\n",
      "190 0.3751824200153351\n",
      "Validation loss: 0.9281048774719238\n",
      "98 Selected hyperparameters: [4, 4, 0.581319382743778] Estimated Loss: -0.27976880967617035 Real Loss: 0.9281048774719238\n",
      "Model created with 9 heads, 2 dimensions per head, and 0.4395200565141957 dropout.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.4593870639801025\n",
      "10 0.574150800704956\n",
      "20 0.5455332398414612\n",
      "30 0.3280576169490814\n",
      "40 0.19343426823616028\n",
      "50 0.2289830446243286\n",
      "60 0.3039708733558655\n",
      "70 0.5945853590965271\n",
      "80 0.25536447763442993\n",
      "90 0.3646804392337799\n",
      "100 0.34366539120674133\n",
      "110 0.2237040400505066\n",
      "120 0.2869998812675476\n",
      "130 0.24293366074562073\n",
      "140 0.3153459429740906\n",
      "150 0.29092225432395935\n",
      "160 0.22696945071220398\n",
      "170 0.2928948998451233\n",
      "180 0.41657567024230957\n",
      "190 0.3037945628166199\n",
      "Validation loss: 0.9634094834327698\n",
      "99 Selected hyperparameters: [2, 9, 0.4395200565141957] Estimated Loss: -1.2483116492803674 Real Loss: 0.9634094834327698\n"
     ]
    }
   ],
   "source": [
    "# Driver for Bayesian Optimization \n",
    "\n",
    "# Initialize surrogate model\n",
    "X = []\n",
    "for samples in range(10):\n",
    "    X.append([random.randint(emb_range[0],emb_range[1])*2, random.randint(heads_range[0],heads_range[1]), random.uniform(dropout_range[0],dropout_range[1])]) # num_heads, emb_per_head, dropout\n",
    "Y = [[objective(x)] for x in X]\n",
    "model = GaussianProcessRegressor()\n",
    "model.fit(X,Y)\n",
    "\n",
    "# Updates to surrogate model\n",
    "from numpy import vstack\n",
    "for iteration in range(100):\n",
    "    # Select the next point to sample with objective function\n",
    "    x = selection(X, model)\n",
    "    # Sample the objective function\n",
    "    actual = objective(x, Y)\n",
    "    # Print findings\n",
    "    est, s = surrogate(model, [x])\n",
    "    print(iteration,'Selected hyperparameters:',x,'Estimated Loss:',est[0][0],'Real Loss:',actual.item())\n",
    "    # Update dataset and surrogate model\n",
    "    X = vstack((X,[x]))\n",
    "    Y = vstack((Y,[[actual]]))\n",
    "    model.fit(X,Y)\n",
    "\n",
    "# Final result\n",
    "out_hyper = min(zip(Y,X))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31430b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "m = torch.load('011023_BO_tenc.pt')\n",
    "\n",
    "# Inference\n",
    "def inference(model, loader):\n",
    "    reals = []\n",
    "    predicteds = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            property_prediction, loss = m(torch.tensor(batch.encsmiles), batch.y)\n",
    "            for i,j in zip(property_prediction, batch.y):\n",
    "                predicteds.append(i.item())\n",
    "                reals.append(j.item())\n",
    "    return reals, predicteds\n",
    "    \n",
    "train_real, train_pred = inference(m, loader)\n",
    "test_real, test_pred = inference(m, test_loader)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aaed73b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN - MSE: 0.27078356467084097 R2: 0.9375495042233242\n",
      "TEST - MSE: 0.9069408391798951 R2: 0.8111751164839524\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Plotting\n",
    "fig,ax = plt.subplots()\n",
    "plt.scatter(train_real, train_pred)\n",
    "plt.scatter(test_real, test_pred)\n",
    "\n",
    "# Formatting\n",
    "plt.xlabel(\"Real Solubility\")\n",
    "plt.ylabel(\"Predicted Solubility\")\n",
    "ax.legend(['Train', 'Test'])\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "ax.set_box_aspect(1)\n",
    "ax.set_xlim(-10,3)\n",
    "ax.set_ylim(-10,3)\n",
    "\n",
    "print('TRAIN - MSE:',mean_squared_error(train_real, train_pred),'R2:',r2_score(train_real, train_pred))\n",
    "print('TEST - MSE:',mean_squared_error(test_real, test_pred),'R2:',r2_score(test_real, test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9e6874cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created with 1 heads, 14 dimensions per head, and 0.028735707903757235 dropout.\n",
      "Epoch 0 Training loss: 7.850566387176514 Validation loss: 3.1464104652404785\n",
      "Epoch 10 Training loss: 0.9807190895080566 Validation loss: 1.0402095317840576\n",
      "Epoch 20 Training loss: 0.3001972436904907 Validation loss: 1.2151854038238525\n",
      "Epoch 30 Training loss: 0.7940494418144226 Validation loss: 0.8708635568618774\n",
      "Epoch 40 Training loss: 0.29379206895828247 Validation loss: 0.9403162598609924\n",
      "Epoch 50 Training loss: 0.4546448588371277 Validation loss: 0.8700158596038818\n",
      "Epoch 60 Training loss: 0.43224743008613586 Validation loss: 0.9181358218193054\n",
      "Epoch 70 Training loss: 0.3138313889503479 Validation loss: 0.9909950494766235\n",
      "Epoch 80 Training loss: 0.3100060224533081 Validation loss: 0.8716793656349182\n",
      "Epoch 90 Training loss: 0.22731563448905945 Validation loss: 0.8702148795127869\n",
      "Epoch 100 Training loss: 0.24553069472312927 Validation loss: 0.9356099367141724\n",
      "Epoch 110 Training loss: 0.2835805118083954 Validation loss: 0.8844519853591919\n",
      "Epoch 120 Training loss: 0.5804700255393982 Validation loss: 0.8531683683395386\n",
      "Epoch 130 Training loss: 0.5228809118270874 Validation loss: 1.0198924541473389\n",
      "Epoch 140 Training loss: 0.260966956615448 Validation loss: 0.8910654187202454\n",
      "Epoch 150 Training loss: 0.1915692836046219 Validation loss: 0.976398766040802\n",
      "Epoch 160 Training loss: 0.7022534608840942 Validation loss: 0.9557106494903564\n",
      "Epoch 170 Training loss: 0.5232917070388794 Validation loss: 0.9900339841842651\n",
      "Epoch 180 Training loss: 0.31479063630104065 Validation loss: 0.9503338932991028\n",
      "Epoch 190 Training loss: 0.3384818136692047 Validation loss: 1.0071390867233276\n",
      "Epoch 200 Training loss: 0.3523252308368683 Validation loss: 1.0107183456420898\n",
      "Epoch 210 Training loss: 0.22812026739120483 Validation loss: 0.8617024421691895\n",
      "Epoch 220 Training loss: 0.32396766543388367 Validation loss: 1.000217080116272\n",
      "Epoch 230 Training loss: 0.16227000951766968 Validation loss: 0.9915258884429932\n",
      "Epoch 240 Training loss: 0.3223561942577362 Validation loss: 1.1370253562927246\n",
      "Epoch 250 Training loss: 0.33871492743492126 Validation loss: 0.910182774066925\n",
      "Epoch 260 Training loss: 0.33515340089797974 Validation loss: 0.9166345000267029\n",
      "Epoch 270 Training loss: 0.42466941475868225 Validation loss: 0.8543028831481934\n",
      "Epoch 280 Training loss: 0.22767946124076843 Validation loss: 0.8998992443084717\n",
      "Epoch 290 Training loss: 0.13171763718128204 Validation loss: 0.8473009467124939\n",
      "Epoch 300 Training loss: 0.2840955853462219 Validation loss: 0.9457328915596008\n",
      "Epoch 310 Training loss: 0.1485355794429779 Validation loss: 1.0698857307434082\n",
      "Epoch 320 Training loss: 0.22731336951255798 Validation loss: 0.9503235816955566\n",
      "Epoch 330 Training loss: 0.29167819023132324 Validation loss: 0.7911146879196167\n",
      "Epoch 340 Training loss: 0.28740742802619934 Validation loss: 0.8797346353530884\n",
      "Epoch 350 Training loss: 0.26767662167549133 Validation loss: 0.9519648551940918\n",
      "Epoch 360 Training loss: 0.27833235263824463 Validation loss: 0.9847699403762817\n",
      "Epoch 370 Training loss: 0.18576115369796753 Validation loss: 0.8695043325424194\n",
      "Epoch 380 Training loss: 0.2266189455986023 Validation loss: 1.0057151317596436\n",
      "Epoch 390 Training loss: 0.25442278385162354 Validation loss: 0.9698535799980164\n",
      "Epoch 400 Training loss: 0.2866310477256775 Validation loss: 0.9389724135398865\n",
      "Epoch 410 Training loss: 0.2025817483663559 Validation loss: 0.8251810073852539\n",
      "Epoch 420 Training loss: 0.13234709203243256 Validation loss: 0.8366622924804688\n",
      "Epoch 430 Training loss: 0.1918036788702011 Validation loss: 0.8950728178024292\n",
      "Epoch 440 Training loss: 0.3266831934452057 Validation loss: 1.0258443355560303\n",
      "Epoch 450 Training loss: 0.20225121080875397 Validation loss: 0.891157865524292\n",
      "Epoch 460 Training loss: 0.24266961216926575 Validation loss: 0.8735111951828003\n",
      "Epoch 470 Training loss: 0.2631097733974457 Validation loss: 0.9089183807373047\n",
      "Epoch 480 Training loss: 0.24618525803089142 Validation loss: 0.9461685419082642\n",
      "Epoch 490 Training loss: 0.2800986170768738 Validation loss: 0.8787541389465332\n",
      "Epoch 500 Training loss: 0.24771460890769958 Validation loss: 1.108266830444336\n",
      "Epoch 510 Training loss: 0.32564854621887207 Validation loss: 0.8696259260177612\n",
      "Epoch 520 Training loss: 0.32686421275138855 Validation loss: 0.8371849656105042\n",
      "Epoch 530 Training loss: 0.17153756320476532 Validation loss: 0.8823931217193604\n",
      "Epoch 540 Training loss: 0.2704472839832306 Validation loss: 1.151761770248413\n",
      "Epoch 550 Training loss: 0.2870311737060547 Validation loss: 0.9115332365036011\n",
      "Epoch 560 Training loss: 0.4022062420845032 Validation loss: 0.8976994752883911\n",
      "Epoch 570 Training loss: 0.2079169899225235 Validation loss: 0.9398197531700134\n",
      "Epoch 580 Training loss: 0.16539721190929413 Validation loss: 1.000521183013916\n",
      "Epoch 590 Training loss: 0.26882031559944153 Validation loss: 0.9900369048118591\n",
      "Epoch 600 Training loss: 0.31323280930519104 Validation loss: 0.8748852014541626\n",
      "Epoch 610 Training loss: 0.19733497500419617 Validation loss: 0.9108402132987976\n",
      "Epoch 620 Training loss: 0.3001255691051483 Validation loss: 0.9511122703552246\n",
      "Epoch 630 Training loss: 0.35214394330978394 Validation loss: 0.8467819690704346\n",
      "Epoch 640 Training loss: 0.3365548551082611 Validation loss: 0.9384975433349609\n",
      "Epoch 650 Training loss: 0.08782988786697388 Validation loss: 0.8628042340278625\n",
      "Epoch 660 Training loss: 0.15935276448726654 Validation loss: 0.8906127214431763\n",
      "Epoch 670 Training loss: 0.18682622909545898 Validation loss: 0.916941225528717\n",
      "Epoch 680 Training loss: 0.1372407078742981 Validation loss: 1.131438970565796\n",
      "Epoch 690 Training loss: 0.2878947854042053 Validation loss: 0.9363837242126465\n",
      "Epoch 700 Training loss: 0.35585471987724304 Validation loss: 1.0145227909088135\n",
      "Epoch 710 Training loss: 0.12239301204681396 Validation loss: 0.9572800397872925\n",
      "Epoch 720 Training loss: 0.15589946508407593 Validation loss: 0.9369120597839355\n",
      "Epoch 730 Training loss: 0.21655882894992828 Validation loss: 1.0241427421569824\n",
      "Epoch 740 Training loss: 0.27526748180389404 Validation loss: 0.9972885251045227\n",
      "Epoch 750 Training loss: 0.14480814337730408 Validation loss: 0.9733221530914307\n",
      "Epoch 760 Training loss: 0.173344224691391 Validation loss: 1.0135608911514282\n",
      "Epoch 770 Training loss: 0.11004401743412018 Validation loss: 1.065615177154541\n",
      "Epoch 780 Training loss: 0.41133835911750793 Validation loss: 0.9195771217346191\n",
      "Epoch 790 Training loss: 0.19061461091041565 Validation loss: 0.9618869423866272\n",
      "Epoch 800 Training loss: 0.246333509683609 Validation loss: 1.042893648147583\n",
      "Epoch 810 Training loss: 0.36940059065818787 Validation loss: 0.9492070078849792\n",
      "Epoch 820 Training loss: 0.13667581975460052 Validation loss: 1.0251041650772095\n",
      "Epoch 830 Training loss: 0.09405145049095154 Validation loss: 1.015299677848816\n",
      "Epoch 840 Training loss: 0.193876251578331 Validation loss: 1.0941014289855957\n",
      "Epoch 850 Training loss: 0.20092655718326569 Validation loss: 1.0339308977127075\n",
      "Epoch 860 Training loss: 0.2972531020641327 Validation loss: 0.9598374366760254\n",
      "Epoch 870 Training loss: 0.07090272009372711 Validation loss: 0.9981057643890381\n",
      "Epoch 880 Training loss: 0.18230554461479187 Validation loss: 1.1310019493103027\n",
      "Epoch 890 Training loss: 0.2875209450721741 Validation loss: 0.8983108997344971\n",
      "Epoch 900 Training loss: 0.23149317502975464 Validation loss: 0.9952901005744934\n",
      "Epoch 910 Training loss: 0.193124458193779 Validation loss: 1.1065731048583984\n",
      "Epoch 920 Training loss: 0.18185336887836456 Validation loss: 1.1265714168548584\n",
      "Epoch 930 Training loss: 0.2647066116333008 Validation loss: 1.2723708152770996\n",
      "Epoch 940 Training loss: 0.1880102902650833 Validation loss: 0.9697079658508301\n",
      "Epoch 950 Training loss: 0.10129459947347641 Validation loss: 1.2669137716293335\n",
      "Epoch 960 Training loss: 0.140785813331604 Validation loss: 1.097434639930725\n",
      "Epoch 970 Training loss: 0.17907275259494781 Validation loss: 1.0545567274093628\n",
      "Epoch 980 Training loss: 0.26577627658843994 Validation loss: 1.0594658851623535\n",
      "Epoch 990 Training loss: 0.24850459396839142 Validation loss: 1.0531851053237915\n",
      "Epoch 1000 Training loss: 0.18696971237659454 Validation loss: 1.0521326065063477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1010 Training loss: 0.10548648238182068 Validation loss: 1.1480565071105957\n",
      "Epoch 1020 Training loss: 0.08782622218132019 Validation loss: 1.0003728866577148\n",
      "Epoch 1030 Training loss: 0.237579807639122 Validation loss: 1.1755255460739136\n",
      "Epoch 1040 Training loss: 0.16471342742443085 Validation loss: 1.0547622442245483\n",
      "Epoch 1050 Training loss: 0.13631893694400787 Validation loss: 0.9254205226898193\n",
      "Epoch 1060 Training loss: 0.17198824882507324 Validation loss: 1.0539417266845703\n",
      "Epoch 1070 Training loss: 0.14278607070446014 Validation loss: 0.9611000418663025\n",
      "Epoch 1080 Training loss: 0.12146350741386414 Validation loss: 1.0973578691482544\n",
      "Epoch 1090 Training loss: 0.08995124697685242 Validation loss: 1.0550066232681274\n",
      "Epoch 1100 Training loss: 0.09554073214530945 Validation loss: 1.0541296005249023\n",
      "Epoch 1110 Training loss: 0.0780305564403534 Validation loss: 1.112302541732788\n",
      "Epoch 1120 Training loss: 0.19778576493263245 Validation loss: 0.9863878488540649\n",
      "Epoch 1130 Training loss: 0.1250133365392685 Validation loss: 1.0328115224838257\n",
      "Epoch 1140 Training loss: 0.22894594073295593 Validation loss: 0.9766886234283447\n",
      "Epoch 1150 Training loss: 0.23598834872245789 Validation loss: 1.110151767730713\n",
      "Epoch 1160 Training loss: 0.13065223395824432 Validation loss: 0.9694690704345703\n",
      "Epoch 1170 Training loss: 0.18027910590171814 Validation loss: 0.9322474002838135\n",
      "Epoch 1180 Training loss: 0.2474425733089447 Validation loss: 1.010742425918579\n",
      "Epoch 1190 Training loss: 0.16837067902088165 Validation loss: 0.9903320074081421\n",
      "Epoch 1200 Training loss: 0.28496044874191284 Validation loss: 0.9984986782073975\n",
      "Epoch 1210 Training loss: 0.14831361174583435 Validation loss: 1.0869470834732056\n",
      "Epoch 1220 Training loss: 0.12788179516792297 Validation loss: 1.0611435174942017\n",
      "Epoch 1230 Training loss: 0.1766727864742279 Validation loss: 1.0451507568359375\n",
      "Epoch 1240 Training loss: 0.14909504354000092 Validation loss: 0.943514883518219\n",
      "Epoch 1250 Training loss: 0.14218543469905853 Validation loss: 0.9485816359519958\n",
      "Epoch 1260 Training loss: 0.19379405677318573 Validation loss: 1.0607370138168335\n",
      "Epoch 1270 Training loss: 0.15183795988559723 Validation loss: 0.9799613356590271\n",
      "Epoch 1280 Training loss: 0.08574537187814713 Validation loss: 0.9846944808959961\n",
      "Epoch 1290 Training loss: 0.12113039940595627 Validation loss: 1.021210789680481\n",
      "Epoch 1300 Training loss: 0.3112381398677826 Validation loss: 0.9853577613830566\n",
      "Epoch 1310 Training loss: 0.10439363121986389 Validation loss: 0.9131205081939697\n",
      "Epoch 1320 Training loss: 0.13492198288440704 Validation loss: 0.9964675903320312\n",
      "Epoch 1330 Training loss: 0.21234458684921265 Validation loss: 1.0856353044509888\n",
      "Epoch 1340 Training loss: 0.18381521105766296 Validation loss: 0.9882267117500305\n",
      "Epoch 1350 Training loss: 0.17052389681339264 Validation loss: 0.9919019341468811\n",
      "Epoch 1360 Training loss: 0.33748361468315125 Validation loss: 1.1177436113357544\n",
      "Epoch 1370 Training loss: 0.09343760460615158 Validation loss: 1.002116084098816\n",
      "Epoch 1380 Training loss: 0.12948155403137207 Validation loss: 1.2433533668518066\n",
      "Epoch 1390 Training loss: 0.10812225192785263 Validation loss: 0.9944515228271484\n",
      "Epoch 1400 Training loss: 0.19260583817958832 Validation loss: 1.0052132606506348\n",
      "Epoch 1410 Training loss: 0.14522938430309296 Validation loss: 0.9436320066452026\n",
      "Epoch 1420 Training loss: 0.25477105379104614 Validation loss: 0.9800329804420471\n",
      "Epoch 1430 Training loss: 0.30449703335762024 Validation loss: 0.9251750707626343\n",
      "Epoch 1440 Training loss: 0.21812371909618378 Validation loss: 0.8970531821250916\n",
      "Epoch 1450 Training loss: 0.12761768698692322 Validation loss: 1.0164538621902466\n",
      "Epoch 1460 Training loss: 0.20147304236888885 Validation loss: 1.1195650100708008\n",
      "Epoch 1470 Training loss: 0.20773708820343018 Validation loss: 0.9426407814025879\n",
      "Epoch 1480 Training loss: 0.0965823158621788 Validation loss: 1.0239770412445068\n",
      "Epoch 1490 Training loss: 0.1637386828660965 Validation loss: 1.0258879661560059\n",
      "Epoch 1500 Training loss: 0.1761152148246765 Validation loss: 1.1157962083816528\n",
      "Epoch 1510 Training loss: 0.20410512387752533 Validation loss: 1.1294715404510498\n",
      "Epoch 1520 Training loss: 0.1719842404127121 Validation loss: 1.012917399406433\n",
      "Epoch 1530 Training loss: 0.23548758029937744 Validation loss: 0.9766230583190918\n",
      "Epoch 1540 Training loss: 0.14242705702781677 Validation loss: 0.9786481857299805\n",
      "Epoch 1550 Training loss: 0.10306646674871445 Validation loss: 0.9913638830184937\n",
      "Epoch 1560 Training loss: 0.0915200486779213 Validation loss: 1.1036162376403809\n",
      "Epoch 1570 Training loss: 0.25702062249183655 Validation loss: 1.159192681312561\n",
      "Epoch 1580 Training loss: 0.2328231930732727 Validation loss: 0.9956883192062378\n",
      "Epoch 1590 Training loss: 0.22466546297073364 Validation loss: 0.9343480467796326\n",
      "Epoch 1600 Training loss: 0.1656084954738617 Validation loss: 1.138223648071289\n",
      "Epoch 1610 Training loss: 0.134967640042305 Validation loss: 1.0571733713150024\n",
      "Epoch 1620 Training loss: 0.144607812166214 Validation loss: 1.0018547773361206\n",
      "Epoch 1630 Training loss: 0.20185136795043945 Validation loss: 0.9814243912696838\n",
      "Epoch 1640 Training loss: 0.2379257082939148 Validation loss: 1.0598622560501099\n",
      "Epoch 1650 Training loss: 0.19972608983516693 Validation loss: 1.0543042421340942\n",
      "Epoch 1660 Training loss: 0.1879592388868332 Validation loss: 1.0142511129379272\n",
      "Epoch 1670 Training loss: 0.12706834077835083 Validation loss: 1.167427897453308\n",
      "Epoch 1680 Training loss: 0.10737115889787674 Validation loss: 1.0674346685409546\n",
      "Epoch 1690 Training loss: 0.11150147020816803 Validation loss: 1.0164365768432617\n",
      "Epoch 1700 Training loss: 0.17132797837257385 Validation loss: 1.1853018999099731\n",
      "Epoch 1710 Training loss: 0.1607212871313095 Validation loss: 1.0582671165466309\n",
      "Epoch 1720 Training loss: 0.1345144361257553 Validation loss: 1.1536898612976074\n",
      "Epoch 1730 Training loss: 0.11115401238203049 Validation loss: 0.9403767585754395\n",
      "Epoch 1740 Training loss: 0.19285790622234344 Validation loss: 0.9135785102844238\n",
      "Epoch 1750 Training loss: 0.15683963894844055 Validation loss: 0.8924963474273682\n",
      "Epoch 1760 Training loss: 0.17690148949623108 Validation loss: 1.1787900924682617\n",
      "Epoch 1770 Training loss: 0.26453015208244324 Validation loss: 0.9269372224807739\n",
      "Epoch 1780 Training loss: 0.12801513075828552 Validation loss: 1.0054349899291992\n",
      "Epoch 1790 Training loss: 0.19703678786754608 Validation loss: 1.0248008966445923\n",
      "Epoch 1800 Training loss: 0.14828136563301086 Validation loss: 0.9997891783714294\n",
      "Epoch 1810 Training loss: 0.13938426971435547 Validation loss: 0.9553968906402588\n",
      "Epoch 1820 Training loss: 0.147160142660141 Validation loss: 0.9766032099723816\n",
      "Epoch 1830 Training loss: 0.20784248411655426 Validation loss: 1.0979825258255005\n",
      "Epoch 1840 Training loss: 0.14056460559368134 Validation loss: 1.0371402502059937\n",
      "Epoch 1850 Training loss: 0.1332550346851349 Validation loss: 1.0263211727142334\n",
      "Epoch 1860 Training loss: 0.20142684876918793 Validation loss: 1.020296335220337\n",
      "Epoch 1870 Training loss: 0.20268367230892181 Validation loss: 1.1427578926086426\n",
      "Epoch 1880 Training loss: 0.15865164995193481 Validation loss: 1.0476683378219604\n",
      "Epoch 1890 Training loss: 0.30367207527160645 Validation loss: 0.8625026345252991\n",
      "Epoch 1900 Training loss: 0.31879982352256775 Validation loss: 0.9659771919250488\n",
      "Epoch 1910 Training loss: 0.08335663378238678 Validation loss: 0.9949619770050049\n",
      "Epoch 1920 Training loss: 0.2159067839384079 Validation loss: 0.9185513257980347\n",
      "Epoch 1930 Training loss: 0.15719546377658844 Validation loss: 1.0585416555404663\n",
      "Epoch 1940 Training loss: 0.13968917727470398 Validation loss: 1.0009775161743164\n",
      "Epoch 1950 Training loss: 0.27288177609443665 Validation loss: 0.8929996490478516\n",
      "Epoch 1960 Training loss: 0.10875565558671951 Validation loss: 0.9797497987747192\n",
      "Epoch 1970 Training loss: 0.14413513243198395 Validation loss: 1.00018310546875\n",
      "Epoch 1980 Training loss: 0.24602971971035004 Validation loss: 1.0270434617996216\n",
      "Epoch 1990 Training loss: 0.25750061869621277 Validation loss: 0.9877548217773438\n",
      "Epoch 2000 Training loss: 0.23751215636730194 Validation loss: 1.0466541051864624\n",
      "Epoch 2010 Training loss: 0.20992235839366913 Validation loss: 1.3186888694763184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2020 Training loss: 0.21032856404781342 Validation loss: 1.0671167373657227\n",
      "Epoch 2030 Training loss: 0.1561085432767868 Validation loss: 0.966394305229187\n",
      "Epoch 2040 Training loss: 0.21499177813529968 Validation loss: 1.0521366596221924\n",
      "Epoch 2050 Training loss: 0.1542392373085022 Validation loss: 0.9430010318756104\n",
      "Epoch 2060 Training loss: 0.15025098621845245 Validation loss: 1.1631274223327637\n",
      "Epoch 2070 Training loss: 0.12047535181045532 Validation loss: 0.984499990940094\n",
      "Epoch 2080 Training loss: 0.14957188069820404 Validation loss: 1.0125534534454346\n",
      "Epoch 2090 Training loss: 0.20278145372867584 Validation loss: 0.9118426442146301\n",
      "Epoch 2100 Training loss: 0.21141016483306885 Validation loss: 0.9737038612365723\n",
      "Epoch 2110 Training loss: 0.05373329296708107 Validation loss: 0.9547432661056519\n",
      "Epoch 2120 Training loss: 0.1188988909125328 Validation loss: 0.9595891237258911\n",
      "Epoch 2130 Training loss: 0.1609198898077011 Validation loss: 0.9820677638053894\n",
      "Epoch 2140 Training loss: 0.20369520783424377 Validation loss: 0.899957537651062\n",
      "Epoch 2150 Training loss: 0.1494874805212021 Validation loss: 1.161557912826538\n",
      "Epoch 2160 Training loss: 0.15800656378269196 Validation loss: 1.0064607858657837\n",
      "Epoch 2170 Training loss: 0.16461290419101715 Validation loss: 1.0480868816375732\n",
      "Epoch 2180 Training loss: 0.24197924137115479 Validation loss: 1.0709631443023682\n",
      "Epoch 2190 Training loss: 0.14228415489196777 Validation loss: 0.8886207342147827\n",
      "Epoch 2200 Training loss: 0.13734382390975952 Validation loss: 0.9617054462432861\n",
      "Epoch 2210 Training loss: 0.18884873390197754 Validation loss: 1.1384581327438354\n",
      "Epoch 2220 Training loss: 0.16129468381404877 Validation loss: 1.1454050540924072\n",
      "Epoch 2230 Training loss: 0.14853261411190033 Validation loss: 1.0004124641418457\n",
      "Epoch 2240 Training loss: 0.10960158705711365 Validation loss: 0.8871748447418213\n",
      "Epoch 2250 Training loss: 0.21548642218112946 Validation loss: 0.9419776201248169\n",
      "Epoch 2260 Training loss: 0.1354021430015564 Validation loss: 0.9167631268501282\n",
      "Epoch 2270 Training loss: 0.1113409772515297 Validation loss: 1.0056424140930176\n",
      "Epoch 2280 Training loss: 0.1538272649049759 Validation loss: 1.069645881652832\n",
      "Epoch 2290 Training loss: 0.2277297079563141 Validation loss: 1.0937106609344482\n",
      "Epoch 2300 Training loss: 0.176698237657547 Validation loss: 0.89094477891922\n",
      "Epoch 2310 Training loss: 0.1871815174818039 Validation loss: 1.110382318496704\n",
      "Epoch 2320 Training loss: 0.15382269024848938 Validation loss: 0.8505984544754028\n",
      "Epoch 2330 Training loss: 0.16194000840187073 Validation loss: 1.0906860828399658\n",
      "Epoch 2340 Training loss: 0.31860294938087463 Validation loss: 0.9545204639434814\n",
      "Epoch 2350 Training loss: 0.13724713027477264 Validation loss: 0.9658578634262085\n",
      "Epoch 2360 Training loss: 0.25900378823280334 Validation loss: 1.050503134727478\n",
      "Epoch 2370 Training loss: 0.15104644000530243 Validation loss: 0.9550745487213135\n",
      "Epoch 2380 Training loss: 0.1455029845237732 Validation loss: 0.9657683372497559\n",
      "Epoch 2390 Training loss: 0.20427533984184265 Validation loss: 0.9428218603134155\n",
      "Epoch 2400 Training loss: 0.4625340402126312 Validation loss: 0.9303853511810303\n",
      "Epoch 2410 Training loss: 0.11051692813634872 Validation loss: 0.9471350908279419\n",
      "Epoch 2420 Training loss: 0.09431743621826172 Validation loss: 0.8869792819023132\n",
      "Epoch 2430 Training loss: 0.09834498912096024 Validation loss: 0.9248502850532532\n",
      "Epoch 2440 Training loss: 0.14303459227085114 Validation loss: 1.067166805267334\n",
      "Epoch 2450 Training loss: 0.22337263822555542 Validation loss: 1.0661303997039795\n",
      "Epoch 2460 Training loss: 0.2268550843000412 Validation loss: 0.9613714814186096\n",
      "Epoch 2470 Training loss: 0.3309780955314636 Validation loss: 1.021274447441101\n",
      "Epoch 2480 Training loss: 0.11532869935035706 Validation loss: 0.8483452796936035\n",
      "Epoch 2490 Training loss: 0.16093532741069794 Validation loss: 1.1489534378051758\n",
      "Epoch 2500 Training loss: 0.14070309698581696 Validation loss: 0.8219280242919922\n",
      "Epoch 2510 Training loss: 0.3464343547821045 Validation loss: 1.0282671451568604\n",
      "Epoch 2520 Training loss: 0.1765487641096115 Validation loss: 1.1810745000839233\n",
      "Epoch 2530 Training loss: 0.16589611768722534 Validation loss: 0.9957919716835022\n",
      "Epoch 2540 Training loss: 0.10437000542879105 Validation loss: 1.054782748222351\n",
      "Epoch 2550 Training loss: 0.11745495349168777 Validation loss: 0.9972825646400452\n",
      "Epoch 2560 Training loss: 0.3098234534263611 Validation loss: 0.9936420321464539\n",
      "Epoch 2570 Training loss: 0.16504426300525665 Validation loss: 1.0950512886047363\n",
      "Epoch 2580 Training loss: 0.12027698755264282 Validation loss: 0.9147599935531616\n",
      "Epoch 2590 Training loss: 0.19699884951114655 Validation loss: 1.0837459564208984\n",
      "Epoch 2600 Training loss: 0.25456878542900085 Validation loss: 0.9050588607788086\n",
      "Epoch 2610 Training loss: 0.1838032752275467 Validation loss: 1.1313947439193726\n",
      "Epoch 2620 Training loss: 0.2405788153409958 Validation loss: 0.908786952495575\n",
      "Epoch 2630 Training loss: 0.29197585582733154 Validation loss: 1.0294638872146606\n",
      "Epoch 2640 Training loss: 0.15585467219352722 Validation loss: 0.8962510824203491\n",
      "Epoch 2650 Training loss: 0.28709450364112854 Validation loss: 1.0231540203094482\n",
      "Epoch 2660 Training loss: 0.08841779083013535 Validation loss: 1.027397632598877\n",
      "Epoch 2670 Training loss: 0.1805650144815445 Validation loss: 1.037420630455017\n",
      "Epoch 2680 Training loss: 0.22235947847366333 Validation loss: 0.820310115814209\n",
      "Epoch 2690 Training loss: 0.20004676282405853 Validation loss: 1.1172735691070557\n",
      "Epoch 2700 Training loss: 0.0997323989868164 Validation loss: 1.1150710582733154\n",
      "Epoch 2710 Training loss: 0.18941406905651093 Validation loss: 0.8842538595199585\n",
      "Epoch 2720 Training loss: 0.14472800493240356 Validation loss: 1.1417043209075928\n",
      "Epoch 2730 Training loss: 0.1493302434682846 Validation loss: 0.9194895029067993\n",
      "Epoch 2740 Training loss: 0.12530769407749176 Validation loss: 0.8825445175170898\n",
      "Epoch 2750 Training loss: 0.1752474009990692 Validation loss: 0.9747930765151978\n",
      "Epoch 2760 Training loss: 0.09549688547849655 Validation loss: 1.158898949623108\n",
      "Epoch 2770 Training loss: 0.15326087176799774 Validation loss: 0.9942930340766907\n",
      "Epoch 2780 Training loss: 0.1114446222782135 Validation loss: 0.932018518447876\n",
      "Epoch 2790 Training loss: 0.09752639383077621 Validation loss: 0.9865999221801758\n",
      "Epoch 2800 Training loss: 0.2670878469944 Validation loss: 0.9059658050537109\n",
      "Epoch 2810 Training loss: 0.12870819866657257 Validation loss: 0.9041014909744263\n",
      "Epoch 2820 Training loss: 0.13349154591560364 Validation loss: 0.9281500577926636\n",
      "Epoch 2830 Training loss: 0.161815345287323 Validation loss: 1.141696810722351\n",
      "Epoch 2840 Training loss: 0.0911504477262497 Validation loss: 0.9517437219619751\n",
      "Epoch 2850 Training loss: 0.14335192739963531 Validation loss: 1.038884162902832\n",
      "Epoch 2860 Training loss: 0.18198707699775696 Validation loss: 0.994552493095398\n",
      "Epoch 2870 Training loss: 0.14572805166244507 Validation loss: 1.0090219974517822\n",
      "Epoch 2880 Training loss: 0.24874676764011383 Validation loss: 1.0323971509933472\n",
      "Epoch 2890 Training loss: 0.20984895527362823 Validation loss: 0.9156220555305481\n",
      "Epoch 2900 Training loss: 0.1290624886751175 Validation loss: 0.9348673224449158\n",
      "Epoch 2910 Training loss: 0.2373509705066681 Validation loss: 1.0539004802703857\n",
      "Epoch 2920 Training loss: 0.13145257532596588 Validation loss: 0.7932089567184448\n",
      "Epoch 2930 Training loss: 0.15488475561141968 Validation loss: 0.8238910436630249\n",
      "Epoch 2940 Training loss: 0.136898934841156 Validation loss: 0.9137439727783203\n",
      "Epoch 2950 Training loss: 0.15688347816467285 Validation loss: 1.070192813873291\n",
      "Epoch 2960 Training loss: 0.13946038484573364 Validation loss: 0.9143351912498474\n",
      "Epoch 2970 Training loss: 0.16781064867973328 Validation loss: 0.9372868537902832\n",
      "Epoch 2980 Training loss: 0.37753093242645264 Validation loss: 0.9900883436203003\n",
      "Epoch 2990 Training loss: 0.16380059719085693 Validation loss: 0.8790156841278076\n"
     ]
    }
   ],
   "source": [
    "# Long Train with Optimized Hyperparameters\n",
    "X = out_hyper\n",
    "emb_per_head = int(X[0])\n",
    "num_heads = int(X[1])\n",
    "dropout = X[2]\n",
    "\n",
    "# Create Model\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "m = Encoder(num_heads*emb_per_head, num_heads, 34, dropout).to(device)\n",
    "optimizer = torch.optim.Adam(m.parameters(), lr=0.01)\n",
    "print('Model created with', num_heads, 'heads,', emb_per_head, 'dimensions per head, and', dropout, 'dropout.')\n",
    "\n",
    "# Train Model\n",
    "avg_val_loss_list = []\n",
    "loss_list = []\n",
    "for epoch in range(3000):\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        property_prediction, loss = m(torch.tensor(batch.encsmiles), batch.y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation Loss\n",
    "    val_losses = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch = batch.to(device)\n",
    "            val_property_prediction, val_loss = m(torch.tensor(batch.encsmiles), batch.y)\n",
    "            val_losses.append(val_loss)\n",
    "    avg_val_loss = sum(val_losses)/len(val_losses)\n",
    "    avg_val_loss_list.append(avg_val_loss.item())\n",
    "    loss_list.append(loss.item())\n",
    "    \n",
    "    # Document\n",
    "    if avg_val_loss.item() <= min(avg_val_loss_list):\n",
    "        torch.save(m,'021023_BO_full_tenc.pt')\n",
    "    if epoch % 10 == 0:\n",
    "        print('Epoch',epoch,'Training loss:',loss.item(),'Validation loss:', avg_val_loss.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ead2a5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN - MSE: 0.2705666971103083 R2: 0.9375995201343327\n",
      "TEST - MSE: 0.7110579085504273 R2: 0.851957899617125\n",
      "Number of Parameters:  2717\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = torch.load('021023_BO_full_tenc.pt')\n",
    "\n",
    "# Inference\n",
    "train_real, train_pred = inference(m, loader)\n",
    "test_real, test_pred = inference(m, test_loader)  \n",
    "\n",
    "# Plotting\n",
    "fig,ax = plt.subplots()\n",
    "plt.scatter(train_real, train_pred)\n",
    "plt.scatter(test_real, test_pred)\n",
    "\n",
    "# Formatting\n",
    "plt.xlabel(\"Real Solubility\")\n",
    "plt.ylabel(\"Predicted Solubility\")\n",
    "ax.legend(['Train', 'Test'])\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "ax.set_box_aspect(1)\n",
    "ax.set_xlim(-10,3)\n",
    "ax.set_ylim(-10,3)\n",
    "\n",
    "print('TRAIN - MSE:',mean_squared_error(train_real, train_pred),'R2:',r2_score(train_real, train_pred))\n",
    "print('TEST - MSE:',mean_squared_error(test_real, test_pred),'R2:',r2_score(test_real, test_pred))\n",
    "print(\"Number of Parameters: \", sum(p.numel() for p in m.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2483e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
